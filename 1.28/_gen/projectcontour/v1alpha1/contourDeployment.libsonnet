{
  local d = (import 'doc-util/main.libsonnet'),
  '#':: d.pkg(name='contourDeployment', url='', help='"ContourDeployment is the schema for a Contour Deployment."'),
  '#metadata':: d.obj(help='"ObjectMeta is metadata that all persisted resources must have, which includes all objects users must create."'),
  metadata: {
    '#withAnnotations':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotations(annotations): { metadata+: { annotations: annotations } },
    '#withAnnotationsMixin':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotationsMixin(annotations): { metadata+: { annotations+: annotations } },
    '#withClusterName':: d.fn(help='"The name of the cluster which the object belongs to. This is used to distinguish resources with same name and namespace in different clusters. This field is not set anywhere right now and apiserver is going to ignore it if set in create or update request."', args=[d.arg(name='clusterName', type=d.T.string)]),
    withClusterName(clusterName): { metadata+: { clusterName: clusterName } },
    '#withCreationTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='creationTimestamp', type=d.T.string)]),
    withCreationTimestamp(creationTimestamp): { metadata+: { creationTimestamp: creationTimestamp } },
    '#withDeletionGracePeriodSeconds':: d.fn(help='"Number of seconds allowed for this object to gracefully terminate before it will be removed from the system. Only set when deletionTimestamp is also set. May only be shortened. Read-only."', args=[d.arg(name='deletionGracePeriodSeconds', type=d.T.integer)]),
    withDeletionGracePeriodSeconds(deletionGracePeriodSeconds): { metadata+: { deletionGracePeriodSeconds: deletionGracePeriodSeconds } },
    '#withDeletionTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='deletionTimestamp', type=d.T.string)]),
    withDeletionTimestamp(deletionTimestamp): { metadata+: { deletionTimestamp: deletionTimestamp } },
    '#withFinalizers':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizers(finalizers): { metadata+: { finalizers: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withFinalizersMixin':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizersMixin(finalizers): { metadata+: { finalizers+: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withGenerateName':: d.fn(help='"GenerateName is an optional prefix, used by the server, to generate a unique name ONLY IF the Name field has not been provided. If this field is used, the name returned to the client will be different than the name passed. This value will also be combined with a unique suffix. The provided value has the same validation rules as the Name field, and may be truncated by the length of the suffix required to make the value unique on the server.\\n\\nIf this field is specified and the generated name exists, the server will NOT return a 409 - instead, it will either return 201 Created or 500 with Reason ServerTimeout indicating a unique name could not be found in the time allotted, and the client should retry (optionally after the time indicated in the Retry-After header).\\n\\nApplied only if Name is not specified. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency"', args=[d.arg(name='generateName', type=d.T.string)]),
    withGenerateName(generateName): { metadata+: { generateName: generateName } },
    '#withGeneration':: d.fn(help='"A sequence number representing a specific generation of the desired state. Populated by the system. Read-only."', args=[d.arg(name='generation', type=d.T.integer)]),
    withGeneration(generation): { metadata+: { generation: generation } },
    '#withLabels':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"', args=[d.arg(name='labels', type=d.T.object)]),
    withLabels(labels): { metadata+: { labels: labels } },
    '#withLabelsMixin':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
    withLabelsMixin(labels): { metadata+: { labels+: labels } },
    '#withName':: d.fn(help='"Name must be unique within a namespace. Is required when creating resources, although some resources may allow a client to request the generation of an appropriate name automatically. Name is primarily intended for creation idempotence and configuration definition. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/identifiers#names"', args=[d.arg(name='name', type=d.T.string)]),
    withName(name): { metadata+: { name: name } },
    '#withNamespace':: d.fn(help='"Namespace defines the space within which each name must be unique. An empty namespace is equivalent to the \\"default\\" namespace, but \\"default\\" is the canonical representation. Not all objects are required to be scoped to a namespace - the value of this field for those objects will be empty.\\n\\nMust be a DNS_LABEL. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/namespaces"', args=[d.arg(name='namespace', type=d.T.string)]),
    withNamespace(namespace): { metadata+: { namespace: namespace } },
    '#withOwnerReferences':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferences(ownerReferences): { metadata+: { ownerReferences: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withOwnerReferencesMixin':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferencesMixin(ownerReferences): { metadata+: { ownerReferences+: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withResourceVersion':: d.fn(help='"An opaque value that represents the internal version of this object that can be used by clients to determine when objects have changed. May be used for optimistic concurrency, change detection, and the watch operation on a resource or set of resources. Clients must treat these values as opaque and passed unmodified back to the server. They may only be valid for a particular resource or set of resources.\\n\\nPopulated by the system. Read-only. Value must be treated as opaque by clients and . More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency"', args=[d.arg(name='resourceVersion', type=d.T.string)]),
    withResourceVersion(resourceVersion): { metadata+: { resourceVersion: resourceVersion } },
    '#withSelfLink':: d.fn(help='"SelfLink is a URL representing this object. Populated by the system. Read-only.\\n\\nDEPRECATED Kubernetes will stop propagating this field in 1.20 release and the field is planned to be removed in 1.21 release."', args=[d.arg(name='selfLink', type=d.T.string)]),
    withSelfLink(selfLink): { metadata+: { selfLink: selfLink } },
    '#withUid':: d.fn(help='"UID is the unique in time and space value for this object. It is typically generated by the server on successful creation of a resource and is not allowed to change on PUT operations.\\n\\nPopulated by the system. Read-only. More info: http://kubernetes.io/docs/user-guide/identifiers#uids"', args=[d.arg(name='uid', type=d.T.string)]),
    withUid(uid): { metadata+: { uid: uid } },
  },
  '#new':: d.fn(help='new returns an instance of ContourDeployment', args=[d.arg(name='name', type=d.T.string)]),
  new(name): {
    apiVersion: 'projectcontour.io/v1alpha1',
    kind: 'ContourDeployment',
  } + self.metadata.withName(name=name),
  '#spec':: d.obj(help='"ContourDeploymentSpec specifies options for how a Contour\\ninstance should be provisioned."'),
  spec: {
    '#contour':: d.obj(help='"Contour specifies deployment-time settings for the Contour\\npart of the installation, i.e. the xDS server/control plane\\nand associated resources, including things like replica count\\nfor the Deployment, and node placement constraints for the pods."'),
    contour: {
      '#deployment':: d.obj(help='"Deployment describes the settings for running contour as a `Deployment`."'),
      deployment: {
        '#strategy':: d.obj(help='"Strategy describes the deployment strategy to use to replace existing pods with new pods."'),
        strategy: {
          '#rollingUpdate':: d.obj(help='"Rolling update config params. Present only if DeploymentStrategyType =\\nRollingUpdate.\\n---\\nTODO: Update this to follow our convention for oneOf, whatever we decide it\\nto be."'),
          rollingUpdate: {
            '#withMaxSurge':: d.fn(help='"The maximum number of pods that can be scheduled above the desired number of\\npods.\\nValue can be an absolute number (ex: 5) or a percentage of desired pods (ex: 10%).\\nThis can not be 0 if MaxUnavailable is 0.\\nAbsolute number is calculated from percentage by rounding up.\\nDefaults to 25%.\\nExample: when this is set to 30%, the new ReplicaSet can be scaled up immediately when\\nthe rolling update starts, such that the total number of old and new pods do not exceed\\n130% of desired pods. Once old pods have been killed,\\nnew ReplicaSet can be scaled up further, ensuring that total number of pods running\\nat any time during the update is at most 130% of desired pods."', args=[d.arg(name='maxSurge', type=d.T.any)]),
            withMaxSurge(maxSurge): { spec+: { contour+: { deployment+: { strategy+: { rollingUpdate+: { maxSurge: maxSurge } } } } } },
            '#withMaxUnavailable':: d.fn(help='"The maximum number of pods that can be unavailable during the update.\\nValue can be an absolute number (ex: 5) or a percentage of desired pods (ex: 10%).\\nAbsolute number is calculated from percentage by rounding down.\\nThis can not be 0 if MaxSurge is 0.\\nDefaults to 25%.\\nExample: when this is set to 30%, the old ReplicaSet can be scaled down to 70% of desired pods\\nimmediately when the rolling update starts. Once new pods are ready, old ReplicaSet\\ncan be scaled down further, followed by scaling up the new ReplicaSet, ensuring\\nthat the total number of pods available at all times during the update is at\\nleast 70% of desired pods."', args=[d.arg(name='maxUnavailable', type=d.T.any)]),
            withMaxUnavailable(maxUnavailable): { spec+: { contour+: { deployment+: { strategy+: { rollingUpdate+: { maxUnavailable: maxUnavailable } } } } } },
          },
          '#withType':: d.fn(help='"Type of deployment. Can be \\"Recreate\\" or \\"RollingUpdate\\". Default is RollingUpdate."', args=[d.arg(name='type', type=d.T.string)]),
          withType(type): { spec+: { contour+: { deployment+: { strategy+: { type: type } } } } },
        },
        '#withReplicas':: d.fn(help='"Replicas is the desired number of replicas."', args=[d.arg(name='replicas', type=d.T.integer)]),
        withReplicas(replicas): { spec+: { contour+: { deployment+: { replicas: replicas } } } },
      },
      '#nodePlacement':: d.obj(help='"NodePlacement describes node scheduling configuration of Contour pods."'),
      nodePlacement: {
        '#tolerations':: d.obj(help='"Tolerations work with taints to ensure that pods are not scheduled\\nonto inappropriate nodes. One or more taints are applied to a node; this\\nmarks that the node should not accept any pods that do not tolerate the\\ntaints.\\nThe default is an empty list.\\nSee https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\\nfor additional details."'),
        tolerations: {
          '#withEffect':: d.fn(help='"Effect indicates the taint effect to match. Empty means match all taint effects.\\nWhen specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute."', args=[d.arg(name='effect', type=d.T.string)]),
          withEffect(effect): { effect: effect },
          '#withKey':: d.fn(help='"Key is the taint key that the toleration applies to. Empty means match all taint keys.\\nIf the key is empty, operator must be Exists; this combination means to match all values and all keys."', args=[d.arg(name='key', type=d.T.string)]),
          withKey(key): { key: key },
          '#withOperator':: d.fn(help="\"Operator represents a key's relationship to the value.\\nValid operators are Exists and Equal. Defaults to Equal.\\nExists is equivalent to wildcard for value, so that a pod can\\ntolerate all taints of a particular category.\"", args=[d.arg(name='operator', type=d.T.string)]),
          withOperator(operator): { operator: operator },
          '#withTolerationSeconds':: d.fn(help='"TolerationSeconds represents the period of time the toleration (which must be\\nof effect NoExecute, otherwise this field is ignored) tolerates the taint. By default,\\nit is not set, which means tolerate the taint forever (do not evict). Zero and\\nnegative values will be treated as 0 (evict immediately) by the system."', args=[d.arg(name='tolerationSeconds', type=d.T.integer)]),
          withTolerationSeconds(tolerationSeconds): { tolerationSeconds: tolerationSeconds },
          '#withValue':: d.fn(help='"Value is the taint value the toleration matches to.\\nIf the operator is Exists, the value should be empty, otherwise just a regular string."', args=[d.arg(name='value', type=d.T.string)]),
          withValue(value): { value: value },
        },
        '#withNodeSelector':: d.fn(help='"NodeSelector is the simplest recommended form of node selection constraint\\nand specifies a map of key-value pairs. For the pod to be eligible\\nto run on a node, the node must have each of the indicated key-value pairs\\nas labels (it can have additional labels as well).\\nIf unset, the pod(s) will be scheduled to any available node."', args=[d.arg(name='nodeSelector', type=d.T.object)]),
        withNodeSelector(nodeSelector): { spec+: { contour+: { nodePlacement+: { nodeSelector: nodeSelector } } } },
        '#withNodeSelectorMixin':: d.fn(help='"NodeSelector is the simplest recommended form of node selection constraint\\nand specifies a map of key-value pairs. For the pod to be eligible\\nto run on a node, the node must have each of the indicated key-value pairs\\nas labels (it can have additional labels as well).\\nIf unset, the pod(s) will be scheduled to any available node."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='nodeSelector', type=d.T.object)]),
        withNodeSelectorMixin(nodeSelector): { spec+: { contour+: { nodePlacement+: { nodeSelector+: nodeSelector } } } },
        '#withTolerations':: d.fn(help='"Tolerations work with taints to ensure that pods are not scheduled\\nonto inappropriate nodes. One or more taints are applied to a node; this\\nmarks that the node should not accept any pods that do not tolerate the\\ntaints.\\nThe default is an empty list.\\nSee https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\\nfor additional details."', args=[d.arg(name='tolerations', type=d.T.array)]),
        withTolerations(tolerations): { spec+: { contour+: { nodePlacement+: { tolerations: if std.isArray(v=tolerations) then tolerations else [tolerations] } } } },
        '#withTolerationsMixin':: d.fn(help='"Tolerations work with taints to ensure that pods are not scheduled\\nonto inappropriate nodes. One or more taints are applied to a node; this\\nmarks that the node should not accept any pods that do not tolerate the\\ntaints.\\nThe default is an empty list.\\nSee https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\\nfor additional details."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='tolerations', type=d.T.array)]),
        withTolerationsMixin(tolerations): { spec+: { contour+: { nodePlacement+: { tolerations+: if std.isArray(v=tolerations) then tolerations else [tolerations] } } } },
      },
      '#resources':: d.obj(help='"Compute Resources required by contour container.\\nCannot be updated.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"'),
      resources: {
        '#claims':: d.obj(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\nThis is an alpha field and requires enabling the\\nDynamicResourceAllocation feature gate.\\nThis field is immutable. It can only be set for containers."'),
        claims: {
          '#withName':: d.fn(help='"Name must match the name of one entry in pod.spec.resourceClaims of\\nthe Pod where this field is used. It makes that resource available\\ninside a container."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { name: name },
        },
        '#withClaims':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\nThis is an alpha field and requires enabling the\\nDynamicResourceAllocation feature gate.\\nThis field is immutable. It can only be set for containers."', args=[d.arg(name='claims', type=d.T.array)]),
        withClaims(claims): { spec+: { contour+: { resources+: { claims: if std.isArray(v=claims) then claims else [claims] } } } },
        '#withClaimsMixin':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\nThis is an alpha field and requires enabling the\\nDynamicResourceAllocation feature gate.\\nThis field is immutable. It can only be set for containers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='claims', type=d.T.array)]),
        withClaimsMixin(claims): { spec+: { contour+: { resources+: { claims+: if std.isArray(v=claims) then claims else [claims] } } } },
        '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
        withLimits(limits): { spec+: { contour+: { resources+: { limits: limits } } } },
        '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
        withLimitsMixin(limits): { spec+: { contour+: { resources+: { limits+: limits } } } },
        '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
        withRequests(requests): { spec+: { contour+: { resources+: { requests: requests } } } },
        '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
        withRequestsMixin(requests): { spec+: { contour+: { resources+: { requests+: requests } } } },
      },
      '#withDisabledFeatures':: d.fn(help='"DisabledFeatures defines an array of resources that will be ignored by\\ncontour reconciler."', args=[d.arg(name='disabledFeatures', type=d.T.array)]),
      withDisabledFeatures(disabledFeatures): { spec+: { contour+: { disabledFeatures: if std.isArray(v=disabledFeatures) then disabledFeatures else [disabledFeatures] } } },
      '#withDisabledFeaturesMixin':: d.fn(help='"DisabledFeatures defines an array of resources that will be ignored by\\ncontour reconciler."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='disabledFeatures', type=d.T.array)]),
      withDisabledFeaturesMixin(disabledFeatures): { spec+: { contour+: { disabledFeatures+: if std.isArray(v=disabledFeatures) then disabledFeatures else [disabledFeatures] } } },
      '#withKubernetesLogLevel':: d.fn(help='"KubernetesLogLevel Enable Kubernetes client debug logging with log level. If unset,\\ndefaults to 0."', args=[d.arg(name='kubernetesLogLevel', type=d.T.integer)]),
      withKubernetesLogLevel(kubernetesLogLevel): { spec+: { contour+: { kubernetesLogLevel: kubernetesLogLevel } } },
      '#withLogLevel':: d.fn(help='"LogLevel sets the log level for Contour\\nAllowed values are \\"info\\", \\"debug\\"."', args=[d.arg(name='logLevel', type=d.T.string)]),
      withLogLevel(logLevel): { spec+: { contour+: { logLevel: logLevel } } },
      '#withPodAnnotations':: d.fn(help='"PodAnnotations defines annotations to add to the Contour pods.\\nthe annotations for Prometheus will be appended or overwritten with predefined value."', args=[d.arg(name='podAnnotations', type=d.T.object)]),
      withPodAnnotations(podAnnotations): { spec+: { contour+: { podAnnotations: podAnnotations } } },
      '#withPodAnnotationsMixin':: d.fn(help='"PodAnnotations defines annotations to add to the Contour pods.\\nthe annotations for Prometheus will be appended or overwritten with predefined value."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='podAnnotations', type=d.T.object)]),
      withPodAnnotationsMixin(podAnnotations): { spec+: { contour+: { podAnnotations+: podAnnotations } } },
      '#withReplicas':: d.fn(help='"Deprecated: Use `DeploymentSettings.Replicas` instead.\\nReplicas is the desired number of Contour replicas. If if unset,\\ndefaults to 2.\\nif both `DeploymentSettings.Replicas` and this one is set, use `DeploymentSettings.Replicas`."', args=[d.arg(name='replicas', type=d.T.integer)]),
      withReplicas(replicas): { spec+: { contour+: { replicas: replicas } } },
      '#withWatchNamespaces':: d.fn(help='"WatchNamespaces is an array of namespaces. Setting it will instruct the contour instance\\nto only watch this subset of namespaces."', args=[d.arg(name='watchNamespaces', type=d.T.array)]),
      withWatchNamespaces(watchNamespaces): { spec+: { contour+: { watchNamespaces: if std.isArray(v=watchNamespaces) then watchNamespaces else [watchNamespaces] } } },
      '#withWatchNamespacesMixin':: d.fn(help='"WatchNamespaces is an array of namespaces. Setting it will instruct the contour instance\\nto only watch this subset of namespaces."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='watchNamespaces', type=d.T.array)]),
      withWatchNamespacesMixin(watchNamespaces): { spec+: { contour+: { watchNamespaces+: if std.isArray(v=watchNamespaces) then watchNamespaces else [watchNamespaces] } } },
    },
    '#envoy':: d.obj(help='"Envoy specifies deployment-time settings for the Envoy\\npart of the installation, i.e. the xDS client/data plane\\nand associated resources, including things like the workload\\ntype to use (DaemonSet or Deployment), node placement constraints\\nfor the pods, and various options for the Envoy service."'),
    envoy: {
      '#daemonSet':: d.obj(help="\"DaemonSet describes the settings for running envoy as a `DaemonSet`.\\nif `WorkloadType` is `Deployment`,it's must be nil\""),
      daemonSet: {
        '#updateStrategy':: d.obj(help='"Strategy describes the deployment strategy to use to replace existing DaemonSet pods with new pods."'),
        updateStrategy: {
          '#rollingUpdate':: d.obj(help='"Rolling update config params. Present only if type = \\"RollingUpdate\\".\\n---\\nTODO: Update this to follow our convention for oneOf, whatever we decide it\\nto be. Same as Deployment `strategy.rollingUpdate`.\\nSee https://github.com/kubernetes/kubernetes/issues/35345"'),
          rollingUpdate: {
            '#withMaxSurge':: d.fn(help='"The maximum number of nodes with an existing available DaemonSet pod that\\ncan have an updated DaemonSet pod during during an update.\\nValue can be an absolute number (ex: 5) or a percentage of desired pods (ex: 10%).\\nThis can not be 0 if MaxUnavailable is 0.\\nAbsolute number is calculated from percentage by rounding up to a minimum of 1.\\nDefault value is 0.\\nExample: when this is set to 30%, at most 30% of the total number of nodes\\nthat should be running the daemon pod (i.e. status.desiredNumberScheduled)\\ncan have their a new pod created before the old pod is marked as deleted.\\nThe update starts by launching new pods on 30% of nodes. Once an updated\\npod is available (Ready for at least minReadySeconds) the old DaemonSet pod\\non that node is marked deleted. If the old pod becomes unavailable for any\\nreason (Ready transitions to false, is evicted, or is drained) an updated\\npod is immediatedly created on that node without considering surge limits.\\nAllowing surge implies the possibility that the resources consumed by the\\ndaemonset on any given node can double if the readiness check fails, and\\nso resource intensive daemonsets should take into account that they may\\ncause evictions during disruption."', args=[d.arg(name='maxSurge', type=d.T.any)]),
            withMaxSurge(maxSurge): { spec+: { envoy+: { daemonSet+: { updateStrategy+: { rollingUpdate+: { maxSurge: maxSurge } } } } } },
            '#withMaxUnavailable':: d.fn(help='"The maximum number of DaemonSet pods that can be unavailable during the\\nupdate. Value can be an absolute number (ex: 5) or a percentage of total\\nnumber of DaemonSet pods at the start of the update (ex: 10%). Absolute\\nnumber is calculated from percentage by rounding up.\\nThis cannot be 0 if MaxSurge is 0\\nDefault value is 1.\\nExample: when this is set to 30%, at most 30% of the total number of nodes\\nthat should be running the daemon pod (i.e. status.desiredNumberScheduled)\\ncan have their pods stopped for an update at any given time. The update\\nstarts by stopping at most 30% of those DaemonSet pods and then brings\\nup new DaemonSet pods in their place. Once the new pods are available,\\nit then proceeds onto other DaemonSet pods, thus ensuring that at least\\n70% of original number of DaemonSet pods are available at all times during\\nthe update."', args=[d.arg(name='maxUnavailable', type=d.T.any)]),
            withMaxUnavailable(maxUnavailable): { spec+: { envoy+: { daemonSet+: { updateStrategy+: { rollingUpdate+: { maxUnavailable: maxUnavailable } } } } } },
          },
          '#withType':: d.fn(help='"Type of daemon set update. Can be \\"RollingUpdate\\" or \\"OnDelete\\". Default is RollingUpdate."', args=[d.arg(name='type', type=d.T.string)]),
          withType(type): { spec+: { envoy+: { daemonSet+: { updateStrategy+: { type: type } } } } },
        },
      },
      '#deployment':: d.obj(help="\"Deployment describes the settings for running envoy as a `Deployment`.\\nif `WorkloadType` is `DaemonSet`,it's must be nil\""),
      deployment: {
        '#strategy':: d.obj(help='"Strategy describes the deployment strategy to use to replace existing pods with new pods."'),
        strategy: {
          '#rollingUpdate':: d.obj(help='"Rolling update config params. Present only if DeploymentStrategyType =\\nRollingUpdate.\\n---\\nTODO: Update this to follow our convention for oneOf, whatever we decide it\\nto be."'),
          rollingUpdate: {
            '#withMaxSurge':: d.fn(help='"The maximum number of pods that can be scheduled above the desired number of\\npods.\\nValue can be an absolute number (ex: 5) or a percentage of desired pods (ex: 10%).\\nThis can not be 0 if MaxUnavailable is 0.\\nAbsolute number is calculated from percentage by rounding up.\\nDefaults to 25%.\\nExample: when this is set to 30%, the new ReplicaSet can be scaled up immediately when\\nthe rolling update starts, such that the total number of old and new pods do not exceed\\n130% of desired pods. Once old pods have been killed,\\nnew ReplicaSet can be scaled up further, ensuring that total number of pods running\\nat any time during the update is at most 130% of desired pods."', args=[d.arg(name='maxSurge', type=d.T.any)]),
            withMaxSurge(maxSurge): { spec+: { envoy+: { deployment+: { strategy+: { rollingUpdate+: { maxSurge: maxSurge } } } } } },
            '#withMaxUnavailable':: d.fn(help='"The maximum number of pods that can be unavailable during the update.\\nValue can be an absolute number (ex: 5) or a percentage of desired pods (ex: 10%).\\nAbsolute number is calculated from percentage by rounding down.\\nThis can not be 0 if MaxSurge is 0.\\nDefaults to 25%.\\nExample: when this is set to 30%, the old ReplicaSet can be scaled down to 70% of desired pods\\nimmediately when the rolling update starts. Once new pods are ready, old ReplicaSet\\ncan be scaled down further, followed by scaling up the new ReplicaSet, ensuring\\nthat the total number of pods available at all times during the update is at\\nleast 70% of desired pods."', args=[d.arg(name='maxUnavailable', type=d.T.any)]),
            withMaxUnavailable(maxUnavailable): { spec+: { envoy+: { deployment+: { strategy+: { rollingUpdate+: { maxUnavailable: maxUnavailable } } } } } },
          },
          '#withType':: d.fn(help='"Type of deployment. Can be \\"Recreate\\" or \\"RollingUpdate\\". Default is RollingUpdate."', args=[d.arg(name='type', type=d.T.string)]),
          withType(type): { spec+: { envoy+: { deployment+: { strategy+: { type: type } } } } },
        },
        '#withReplicas':: d.fn(help='"Replicas is the desired number of replicas."', args=[d.arg(name='replicas', type=d.T.integer)]),
        withReplicas(replicas): { spec+: { envoy+: { deployment+: { replicas: replicas } } } },
      },
      '#extraVolumeMounts':: d.obj(help='"ExtraVolumeMounts holds the extra volume mounts to add (normally used with extraVolumes)."'),
      extraVolumeMounts: {
        '#withMountPath':: d.fn(help="\"Path within the container at which the volume should be mounted.  Must\\nnot contain ':'.\"", args=[d.arg(name='mountPath', type=d.T.string)]),
        withMountPath(mountPath): { mountPath: mountPath },
        '#withMountPropagation':: d.fn(help='"mountPropagation determines how mounts are propagated from the host\\nto container and the other way around.\\nWhen not set, MountPropagationNone is used.\\nThis field is beta in 1.10."', args=[d.arg(name='mountPropagation', type=d.T.string)]),
        withMountPropagation(mountPropagation): { mountPropagation: mountPropagation },
        '#withName':: d.fn(help='"This must match the Name of a Volume."', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { name: name },
        '#withReadOnly':: d.fn(help='"Mounted read-only if true, read-write otherwise (false or unspecified).\\nDefaults to false."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
        withReadOnly(readOnly): { readOnly: readOnly },
        '#withSubPath':: d.fn(help="\"Path within the volume from which the container's volume should be mounted.\\nDefaults to \\\"\\\" (volume's root).\"", args=[d.arg(name='subPath', type=d.T.string)]),
        withSubPath(subPath): { subPath: subPath },
        '#withSubPathExpr':: d.fn(help="\"Expanded path within the volume from which the container's volume should be mounted.\\nBehaves similarly to SubPath but environment variable references $(VAR_NAME) are expanded using the container's environment.\\nDefaults to \\\"\\\" (volume's root).\\nSubPathExpr and SubPath are mutually exclusive.\"", args=[d.arg(name='subPathExpr', type=d.T.string)]),
        withSubPathExpr(subPathExpr): { subPathExpr: subPathExpr },
      },
      '#extraVolumes':: d.obj(help='"ExtraVolumes holds the extra volumes to add."'),
      extraVolumes: {
        '#awsElasticBlockStore':: d.obj(help="\"awsElasticBlockStore represents an AWS Disk resource that is attached to a\\nkubelet's host machine and then exposed to the pod.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore\""),
        awsElasticBlockStore: {
          '#withFsType':: d.fn(help='"fsType is the filesystem type of the volume that you want to mount.\\nTip: Ensure that the filesystem type is supported by the host operating system.\\nExamples: \\"ext4\\", \\"xfs\\", \\"ntfs\\". Implicitly inferred to be \\"ext4\\" if unspecified.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore\\nTODO: how do we prevent errors in the filesystem from compromising the machine"', args=[d.arg(name='fsType', type=d.T.string)]),
          withFsType(fsType): { awsElasticBlockStore+: { fsType: fsType } },
          '#withPartition':: d.fn(help='"partition is the partition in the volume that you want to mount.\\nIf omitted, the default is to mount by volume name.\\nExamples: For volume /dev/sda1, you specify the partition as \\"1\\".\\nSimilarly, the volume partition for /dev/sda is \\"0\\" (or you can leave the property empty)."', args=[d.arg(name='partition', type=d.T.integer)]),
          withPartition(partition): { awsElasticBlockStore+: { partition: partition } },
          '#withReadOnly':: d.fn(help='"readOnly value true will force the readOnly setting in VolumeMounts.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore"', args=[d.arg(name='readOnly', type=d.T.boolean)]),
          withReadOnly(readOnly): { awsElasticBlockStore+: { readOnly: readOnly } },
          '#withVolumeID':: d.fn(help='"volumeID is unique ID of the persistent disk resource in AWS (Amazon EBS volume).\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore"', args=[d.arg(name='volumeID', type=d.T.string)]),
          withVolumeID(volumeID): { awsElasticBlockStore+: { volumeID: volumeID } },
        },
        '#azureDisk':: d.obj(help='"azureDisk represents an Azure Data Disk mount on the host and bind mount to the pod."'),
        azureDisk: {
          '#withCachingMode':: d.fn(help='"cachingMode is the Host Caching mode: None, Read Only, Read Write."', args=[d.arg(name='cachingMode', type=d.T.string)]),
          withCachingMode(cachingMode): { azureDisk+: { cachingMode: cachingMode } },
          '#withDiskName':: d.fn(help='"diskName is the Name of the data disk in the blob storage"', args=[d.arg(name='diskName', type=d.T.string)]),
          withDiskName(diskName): { azureDisk+: { diskName: diskName } },
          '#withDiskURI':: d.fn(help='"diskURI is the URI of data disk in the blob storage"', args=[d.arg(name='diskURI', type=d.T.string)]),
          withDiskURI(diskURI): { azureDisk+: { diskURI: diskURI } },
          '#withFsType':: d.fn(help='"fsType is Filesystem type to mount.\\nMust be a filesystem type supported by the host operating system.\\nEx. \\"ext4\\", \\"xfs\\", \\"ntfs\\". Implicitly inferred to be \\"ext4\\" if unspecified."', args=[d.arg(name='fsType', type=d.T.string)]),
          withFsType(fsType): { azureDisk+: { fsType: fsType } },
          '#withKind':: d.fn(help='"kind expected values are Shared: multiple blob disks per storage account  Dedicated: single blob disk per storage account  Managed: azure managed data disk (only in managed availability set). defaults to shared"', args=[d.arg(name='kind', type=d.T.string)]),
          withKind(kind): { azureDisk+: { kind: kind } },
          '#withReadOnly':: d.fn(help='"readOnly Defaults to false (read/write). ReadOnly here will force\\nthe ReadOnly setting in VolumeMounts."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
          withReadOnly(readOnly): { azureDisk+: { readOnly: readOnly } },
        },
        '#azureFile':: d.obj(help='"azureFile represents an Azure File Service mount on the host and bind mount to the pod."'),
        azureFile: {
          '#withReadOnly':: d.fn(help='"readOnly defaults to false (read/write). ReadOnly here will force\\nthe ReadOnly setting in VolumeMounts."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
          withReadOnly(readOnly): { azureFile+: { readOnly: readOnly } },
          '#withSecretName':: d.fn(help='"secretName is the  name of secret that contains Azure Storage Account Name and Key"', args=[d.arg(name='secretName', type=d.T.string)]),
          withSecretName(secretName): { azureFile+: { secretName: secretName } },
          '#withShareName':: d.fn(help='"shareName is the azure share Name"', args=[d.arg(name='shareName', type=d.T.string)]),
          withShareName(shareName): { azureFile+: { shareName: shareName } },
        },
        '#cephfs':: d.obj(help="\"cephFS represents a Ceph FS mount on the host that shares a pod's lifetime\""),
        cephfs: {
          '#secretRef':: d.obj(help='"secretRef is Optional: SecretRef is reference to the authentication secret for User, default is empty.\\nMore info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it"'),
          secretRef: {
            '#withName':: d.fn(help='"Name of the referent.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names\\nTODO: Add other useful fields. apiVersion, kind, uid?"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { cephfs+: { secretRef+: { name: name } } },
          },
          '#withMonitors':: d.fn(help='"monitors is Required: Monitors is a collection of Ceph monitors\\nMore info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it"', args=[d.arg(name='monitors', type=d.T.array)]),
          withMonitors(monitors): { cephfs+: { monitors: if std.isArray(v=monitors) then monitors else [monitors] } },
          '#withMonitorsMixin':: d.fn(help='"monitors is Required: Monitors is a collection of Ceph monitors\\nMore info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='monitors', type=d.T.array)]),
          withMonitorsMixin(monitors): { cephfs+: { monitors+: if std.isArray(v=monitors) then monitors else [monitors] } },
          '#withPath':: d.fn(help='"path is Optional: Used as the mounted root, rather than the full Ceph tree, default is /"', args=[d.arg(name='path', type=d.T.string)]),
          withPath(path): { cephfs+: { path: path } },
          '#withReadOnly':: d.fn(help='"readOnly is Optional: Defaults to false (read/write). ReadOnly here will force\\nthe ReadOnly setting in VolumeMounts.\\nMore info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it"', args=[d.arg(name='readOnly', type=d.T.boolean)]),
          withReadOnly(readOnly): { cephfs+: { readOnly: readOnly } },
          '#withSecretFile':: d.fn(help='"secretFile is Optional: SecretFile is the path to key ring for User, default is /etc/ceph/user.secret\\nMore info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it"', args=[d.arg(name='secretFile', type=d.T.string)]),
          withSecretFile(secretFile): { cephfs+: { secretFile: secretFile } },
          '#withUser':: d.fn(help='"user is optional: User is the rados user name, default is admin\\nMore info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it"', args=[d.arg(name='user', type=d.T.string)]),
          withUser(user): { cephfs+: { user: user } },
        },
        '#cinder':: d.obj(help='"cinder represents a cinder volume attached and mounted on kubelets host machine.\\nMore info: https://examples.k8s.io/mysql-cinder-pd/README.md"'),
        cinder: {
          '#secretRef':: d.obj(help='"secretRef is optional: points to a secret object containing parameters used to connect\\nto OpenStack."'),
          secretRef: {
            '#withName':: d.fn(help='"Name of the referent.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names\\nTODO: Add other useful fields. apiVersion, kind, uid?"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { cinder+: { secretRef+: { name: name } } },
          },
          '#withFsType':: d.fn(help='"fsType is the filesystem type to mount.\\nMust be a filesystem type supported by the host operating system.\\nExamples: \\"ext4\\", \\"xfs\\", \\"ntfs\\". Implicitly inferred to be \\"ext4\\" if unspecified.\\nMore info: https://examples.k8s.io/mysql-cinder-pd/README.md"', args=[d.arg(name='fsType', type=d.T.string)]),
          withFsType(fsType): { cinder+: { fsType: fsType } },
          '#withReadOnly':: d.fn(help='"readOnly defaults to false (read/write). ReadOnly here will force\\nthe ReadOnly setting in VolumeMounts.\\nMore info: https://examples.k8s.io/mysql-cinder-pd/README.md"', args=[d.arg(name='readOnly', type=d.T.boolean)]),
          withReadOnly(readOnly): { cinder+: { readOnly: readOnly } },
          '#withVolumeID':: d.fn(help='"volumeID used to identify the volume in cinder.\\nMore info: https://examples.k8s.io/mysql-cinder-pd/README.md"', args=[d.arg(name='volumeID', type=d.T.string)]),
          withVolumeID(volumeID): { cinder+: { volumeID: volumeID } },
        },
        '#configMap':: d.obj(help='"configMap represents a configMap that should populate this volume"'),
        configMap: {
          '#items':: d.obj(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nConfigMap will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the ConfigMap,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\""),
          items: {
            '#withKey':: d.fn(help='"key is the key to project."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { key: key },
            '#withMode':: d.fn(help='"mode is Optional: mode bits used to set permissions on this file.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
            withMode(mode): { mode: mode },
            '#withPath':: d.fn(help="\"path is the relative path of the file to map the key to.\\nMay not be an absolute path.\\nMay not contain the path element '..'.\\nMay not start with the string '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
            withPath(path): { path: path },
          },
          '#withDefaultMode':: d.fn(help='"defaultMode is optional: mode bits used to set permissions on created files by default.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nDefaults to 0644.\\nDirectories within the path are not affected by this setting.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='defaultMode', type=d.T.integer)]),
          withDefaultMode(defaultMode): { configMap+: { defaultMode: defaultMode } },
          '#withItems':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nConfigMap will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the ConfigMap,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"", args=[d.arg(name='items', type=d.T.array)]),
          withItems(items): { configMap+: { items: if std.isArray(v=items) then items else [items] } },
          '#withItemsMixin':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nConfigMap will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the ConfigMap,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='items', type=d.T.array)]),
          withItemsMixin(items): { configMap+: { items+: if std.isArray(v=items) then items else [items] } },
          '#withName':: d.fn(help='"Name of the referent.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names\\nTODO: Add other useful fields. apiVersion, kind, uid?"', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { configMap+: { name: name } },
          '#withOptional':: d.fn(help='"optional specify whether the ConfigMap or its keys must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
          withOptional(optional): { configMap+: { optional: optional } },
        },
        '#csi':: d.obj(help='"csi (Container Storage Interface) represents ephemeral storage that is handled by certain external CSI drivers (Beta feature)."'),
        csi: {
          '#nodePublishSecretRef':: d.obj(help='"nodePublishSecretRef is a reference to the secret object containing\\nsensitive information to pass to the CSI driver to complete the CSI\\nNodePublishVolume and NodeUnpublishVolume calls.\\nThis field is optional, and  may be empty if no secret is required. If the\\nsecret object contains more than one secret, all secret references are passed."'),
          nodePublishSecretRef: {
            '#withName':: d.fn(help='"Name of the referent.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names\\nTODO: Add other useful fields. apiVersion, kind, uid?"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { csi+: { nodePublishSecretRef+: { name: name } } },
          },
          '#withDriver':: d.fn(help='"driver is the name of the CSI driver that handles this volume.\\nConsult with your admin for the correct name as registered in the cluster."', args=[d.arg(name='driver', type=d.T.string)]),
          withDriver(driver): { csi+: { driver: driver } },
          '#withFsType':: d.fn(help='"fsType to mount. Ex. \\"ext4\\", \\"xfs\\", \\"ntfs\\".\\nIf not provided, the empty value is passed to the associated CSI driver\\nwhich will determine the default filesystem to apply."', args=[d.arg(name='fsType', type=d.T.string)]),
          withFsType(fsType): { csi+: { fsType: fsType } },
          '#withReadOnly':: d.fn(help='"readOnly specifies a read-only configuration for the volume.\\nDefaults to false (read/write)."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
          withReadOnly(readOnly): { csi+: { readOnly: readOnly } },
          '#withVolumeAttributes':: d.fn(help="\"volumeAttributes stores driver-specific properties that are passed to the CSI\\ndriver. Consult your driver's documentation for supported values.\"", args=[d.arg(name='volumeAttributes', type=d.T.object)]),
          withVolumeAttributes(volumeAttributes): { csi+: { volumeAttributes: volumeAttributes } },
          '#withVolumeAttributesMixin':: d.fn(help="\"volumeAttributes stores driver-specific properties that are passed to the CSI\\ndriver. Consult your driver's documentation for supported values.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='volumeAttributes', type=d.T.object)]),
          withVolumeAttributesMixin(volumeAttributes): { csi+: { volumeAttributes+: volumeAttributes } },
        },
        '#downwardAPI':: d.obj(help='"downwardAPI represents downward API about the pod that should populate this volume"'),
        downwardAPI: {
          '#items':: d.obj(help='"Items is a list of downward API volume file"'),
          items: {
            '#fieldRef':: d.obj(help='"Required: Selects a field of the pod: only annotations, labels, name and namespace are supported."'),
            fieldRef: {
              '#withApiVersion':: d.fn(help='"Version of the schema the FieldPath is written in terms of, defaults to \\"v1\\"."', args=[d.arg(name='apiVersion', type=d.T.string)]),
              withApiVersion(apiVersion): { fieldRef+: { apiVersion: apiVersion } },
              '#withFieldPath':: d.fn(help='"Path of the field to select in the specified API version."', args=[d.arg(name='fieldPath', type=d.T.string)]),
              withFieldPath(fieldPath): { fieldRef+: { fieldPath: fieldPath } },
            },
            '#resourceFieldRef':: d.obj(help='"Selects a resource of the container: only resources limits and requests\\n(limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported."'),
            resourceFieldRef: {
              '#withContainerName':: d.fn(help='"Container name: required for volumes, optional for env vars"', args=[d.arg(name='containerName', type=d.T.string)]),
              withContainerName(containerName): { resourceFieldRef+: { containerName: containerName } },
              '#withDivisor':: d.fn(help='"Specifies the output format of the exposed resources, defaults to \\"1\\', args=[d.arg(name='divisor', type=d.T.any)]),
              withDivisor(divisor): { resourceFieldRef+: { divisor: divisor } },
              '#withResource':: d.fn(help='"Required: resource to select"', args=[d.arg(name='resource', type=d.T.string)]),
              withResource(resource): { resourceFieldRef+: { resource: resource } },
            },
            '#withMode':: d.fn(help='"Optional: mode bits used to set permissions on this file, must be an octal value\\nbetween 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
            withMode(mode): { mode: mode },
            '#withPath':: d.fn(help="\"Required: Path is  the relative path name of the file to be created. Must not be absolute or contain the '..' path. Must be utf-8 encoded. The first item of the relative path must not start with '..'\"", args=[d.arg(name='path', type=d.T.string)]),
            withPath(path): { path: path },
          },
          '#withDefaultMode':: d.fn(help='"Optional: mode bits to use on created files by default. Must be a\\nOptional: mode bits used to set permissions on created files by default.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nDefaults to 0644.\\nDirectories within the path are not affected by this setting.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='defaultMode', type=d.T.integer)]),
          withDefaultMode(defaultMode): { downwardAPI+: { defaultMode: defaultMode } },
          '#withItems':: d.fn(help='"Items is a list of downward API volume file"', args=[d.arg(name='items', type=d.T.array)]),
          withItems(items): { downwardAPI+: { items: if std.isArray(v=items) then items else [items] } },
          '#withItemsMixin':: d.fn(help='"Items is a list of downward API volume file"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='items', type=d.T.array)]),
          withItemsMixin(items): { downwardAPI+: { items+: if std.isArray(v=items) then items else [items] } },
        },
        '#emptyDir':: d.obj(help="\"emptyDir represents a temporary directory that shares a pod's lifetime.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir\""),
        emptyDir: {
          '#withMedium':: d.fn(help="\"medium represents what type of storage medium should back this directory.\\nThe default is \\\"\\\" which means to use the node's default medium.\\nMust be an empty string (default) or Memory.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir\"", args=[d.arg(name='medium', type=d.T.string)]),
          withMedium(medium): { emptyDir+: { medium: medium } },
          '#withSizeLimit':: d.fn(help='"sizeLimit is the total amount of local storage required for this EmptyDir volume.\\nThe size limit is also applicable for memory medium.\\nThe maximum usage on memory medium EmptyDir would be the minimum value between\\nthe SizeLimit specified here and the sum of memory limits of all containers in a pod.\\nThe default is nil which means that the limit is undefined.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir"', args=[d.arg(name='sizeLimit', type=d.T.any)]),
          withSizeLimit(sizeLimit): { emptyDir+: { sizeLimit: sizeLimit } },
        },
        '#ephemeral':: d.obj(help="\"ephemeral represents a volume that is handled by a cluster storage driver.\\nThe volume's lifecycle is tied to the pod that defines it - it will be created before the pod starts,\\nand deleted when the pod is removed.\\nUse this if:\\na) the volume is only needed while the pod runs,\\nb) features of normal volumes like restoring from snapshot or capacity\\n   tracking are needed,\\nc) the storage driver is specified through a storage class, and\\nd) the storage driver supports dynamic volume provisioning through\\n   a PersistentVolumeClaim (see EphemeralVolumeSource for more\\n   information on the connection between this volume type\\n   and PersistentVolumeClaim).\\nUse PersistentVolumeClaim or one of the vendor-specific\\nAPIs for volumes that persist for longer than the lifecycle\\nof an individual pod.\\nUse CSI for light-weight local ephemeral volumes if the CSI driver is meant to\\nbe used that way - see the documentation of the driver for\\nmore information.\\nA pod can use both types of ephemeral volumes and\\npersistent volumes at the same time.\""),
        ephemeral: {
          '#volumeClaimTemplate':: d.obj(help='"Will be used to create a stand-alone PVC to provision the volume.\\nThe pod in which this EphemeralVolumeSource is embedded will be the\\nowner of the PVC, i.e. the PVC will be deleted together with the\\npod.  The name of the PVC will be `<pod name>-<volume name>` where\\n`<volume name>` is the name from the `PodSpec.Volumes` array\\nentry. Pod validation will reject the pod if the concatenated name\\nis not valid for a PVC (for example, too long).\\nAn existing PVC with that name that is not owned by the pod\\nwill *not* be used for the pod to avoid using an unrelated\\nvolume by mistake. Starting the pod is then blocked until\\nthe unrelated PVC is removed. If such a pre-created PVC is\\nmeant to be used by the pod, the PVC has to updated with an\\nowner reference to the pod once the pod exists. Normally\\nthis should not be necessary, but it may be useful when\\nmanually reconstructing a broken cluster.\\nThis field is read-only and no changes will be made by Kubernetes\\nto the PVC after it has been created.\\nRequired, must not be nil."'),
          volumeClaimTemplate: {
            '#spec':: d.obj(help='"The specification for the PersistentVolumeClaim. The entire content is\\ncopied unchanged into the PVC that gets created from this\\ntemplate. The same fields as in a PersistentVolumeClaim\\nare also valid here."'),
            spec: {
              '#dataSource':: d.obj(help='"dataSource field can be used to specify either:\\n* An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot)\\n* An existing PVC (PersistentVolumeClaim)\\nIf the provisioner or an external controller can support the specified data source,\\nit will create a new volume based on the contents of the specified data source.\\nWhen the AnyVolumeDataSource feature gate is enabled, dataSource contents will be copied to dataSourceRef,\\nand dataSourceRef contents will be copied to dataSource when dataSourceRef.namespace is not specified.\\nIf the namespace is specified, then dataSourceRef will not be copied to dataSource."'),
              dataSource: {
                '#withApiGroup':: d.fn(help='"APIGroup is the group for the resource being referenced.\\nIf APIGroup is not specified, the specified Kind must be in the core API group.\\nFor any other third-party types, APIGroup is required."', args=[d.arg(name='apiGroup', type=d.T.string)]),
                withApiGroup(apiGroup): { ephemeral+: { volumeClaimTemplate+: { spec+: { dataSource+: { apiGroup: apiGroup } } } } },
                '#withKind':: d.fn(help='"Kind is the type of resource being referenced"', args=[d.arg(name='kind', type=d.T.string)]),
                withKind(kind): { ephemeral+: { volumeClaimTemplate+: { spec+: { dataSource+: { kind: kind } } } } },
                '#withName':: d.fn(help='"Name is the name of resource being referenced"', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { ephemeral+: { volumeClaimTemplate+: { spec+: { dataSource+: { name: name } } } } },
              },
              '#dataSourceRef':: d.obj(help="\"dataSourceRef specifies the object from which to populate the volume with data, if a non-empty\\nvolume is desired. This may be any object from a non-empty API group (non\\ncore object) or a PersistentVolumeClaim object.\\nWhen this field is specified, volume binding will only succeed if the type of\\nthe specified object matches some installed volume populator or dynamic\\nprovisioner.\\nThis field will replace the functionality of the dataSource field and as such\\nif both fields are non-empty, they must have the same value. For backwards\\ncompatibility, when namespace isn't specified in dataSourceRef,\\nboth fields (dataSource and dataSourceRef) will be set to the same\\nvalue automatically if one of them is empty and the other is non-empty.\\nWhen namespace is specified in dataSourceRef,\\ndataSource isn't set to the same value and must be empty.\\nThere are three important differences between dataSource and dataSourceRef:\\n* While dataSource only allows two specific types of objects, dataSourceRef\\n  allows any non-core object, as well as PersistentVolumeClaim objects.\\n* While dataSource ignores disallowed values (dropping them), dataSourceRef\\n  preserves all values, and generates an error if a disallowed value is\\n  specified.\\n* While dataSource only allows local objects, dataSourceRef allows objects\\n  in any namespaces.\\n(Beta) Using this field requires the AnyVolumeDataSource feature gate to be enabled.\\n(Alpha) Using the namespace field of dataSourceRef requires the CrossNamespaceVolumeDataSource feature gate to be enabled.\""),
              dataSourceRef: {
                '#withApiGroup':: d.fn(help='"APIGroup is the group for the resource being referenced.\\nIf APIGroup is not specified, the specified Kind must be in the core API group.\\nFor any other third-party types, APIGroup is required."', args=[d.arg(name='apiGroup', type=d.T.string)]),
                withApiGroup(apiGroup): { ephemeral+: { volumeClaimTemplate+: { spec+: { dataSourceRef+: { apiGroup: apiGroup } } } } },
                '#withKind':: d.fn(help='"Kind is the type of resource being referenced"', args=[d.arg(name='kind', type=d.T.string)]),
                withKind(kind): { ephemeral+: { volumeClaimTemplate+: { spec+: { dataSourceRef+: { kind: kind } } } } },
                '#withName':: d.fn(help='"Name is the name of resource being referenced"', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { ephemeral+: { volumeClaimTemplate+: { spec+: { dataSourceRef+: { name: name } } } } },
                '#withNamespace':: d.fn(help="\"Namespace is the namespace of resource being referenced\\nNote that when a namespace is specified, a gateway.networking.k8s.io/ReferenceGrant object is required in the referent namespace to allow that namespace's owner to accept the reference. See the ReferenceGrant documentation for details.\\n(Alpha) This field requires the CrossNamespaceVolumeDataSource feature gate to be enabled.\"", args=[d.arg(name='namespace', type=d.T.string)]),
                withNamespace(namespace): { ephemeral+: { volumeClaimTemplate+: { spec+: { dataSourceRef+: { namespace: namespace } } } } },
              },
              '#resources':: d.obj(help='"resources represents the minimum resources the volume should have.\\nIf RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements\\nthat are lower than previous value but must still be higher than capacity recorded in the\\nstatus field of the claim.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources"'),
              resources: {
                '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
                withLimits(limits): { ephemeral+: { volumeClaimTemplate+: { spec+: { resources+: { limits: limits } } } } },
                '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
                withLimitsMixin(limits): { ephemeral+: { volumeClaimTemplate+: { spec+: { resources+: { limits+: limits } } } } },
                '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
                withRequests(requests): { ephemeral+: { volumeClaimTemplate+: { spec+: { resources+: { requests: requests } } } } },
                '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
                withRequestsMixin(requests): { ephemeral+: { volumeClaimTemplate+: { spec+: { resources+: { requests+: requests } } } } },
              },
              '#selector':: d.obj(help='"selector is a label query over volumes to consider for binding."'),
              selector: {
                '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                matchExpressions: {
                  '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { ephemeral+: { volumeClaimTemplate+: { spec+: { selector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } } } },
                '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { ephemeral+: { volumeClaimTemplate+: { spec+: { selector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } } } },
                '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabels(matchLabels): { ephemeral+: { volumeClaimTemplate+: { spec+: { selector+: { matchLabels: matchLabels } } } } },
                '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabelsMixin(matchLabels): { ephemeral+: { volumeClaimTemplate+: { spec+: { selector+: { matchLabels+: matchLabels } } } } },
              },
              '#withAccessModes':: d.fn(help='"accessModes contains the desired access modes the volume should have.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1"', args=[d.arg(name='accessModes', type=d.T.array)]),
              withAccessModes(accessModes): { ephemeral+: { volumeClaimTemplate+: { spec+: { accessModes: if std.isArray(v=accessModes) then accessModes else [accessModes] } } } },
              '#withAccessModesMixin':: d.fn(help='"accessModes contains the desired access modes the volume should have.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='accessModes', type=d.T.array)]),
              withAccessModesMixin(accessModes): { ephemeral+: { volumeClaimTemplate+: { spec+: { accessModes+: if std.isArray(v=accessModes) then accessModes else [accessModes] } } } },
              '#withStorageClassName':: d.fn(help='"storageClassName is the name of the StorageClass required by the claim.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1"', args=[d.arg(name='storageClassName', type=d.T.string)]),
              withStorageClassName(storageClassName): { ephemeral+: { volumeClaimTemplate+: { spec+: { storageClassName: storageClassName } } } },
              '#withVolumeAttributesClassName':: d.fn(help="\"volumeAttributesClassName may be used to set the VolumeAttributesClass used by this claim.\\nIf specified, the CSI driver will create or update the volume with the attributes defined\\nin the corresponding VolumeAttributesClass. This has a different purpose than storageClassName,\\nit can be changed after the claim is created. An empty string value means that no VolumeAttributesClass\\nwill be applied to the claim but it's not allowed to reset this field to empty string once it is set.\\nIf unspecified and the PersistentVolumeClaim is unbound, the default VolumeAttributesClass\\nwill be set by the persistentvolume controller if it exists.\\nIf the resource referred to by volumeAttributesClass does not exist, this PersistentVolumeClaim will be\\nset to a Pending state, as reflected by the modifyVolumeStatus field, until such as a resource\\nexists.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#volumeattributesclass\\n(Alpha) Using this field requires the VolumeAttributesClass feature gate to be enabled.\"", args=[d.arg(name='volumeAttributesClassName', type=d.T.string)]),
              withVolumeAttributesClassName(volumeAttributesClassName): { ephemeral+: { volumeClaimTemplate+: { spec+: { volumeAttributesClassName: volumeAttributesClassName } } } },
              '#withVolumeMode':: d.fn(help='"volumeMode defines what type of volume is required by the claim.\\nValue of Filesystem is implied when not included in claim spec."', args=[d.arg(name='volumeMode', type=d.T.string)]),
              withVolumeMode(volumeMode): { ephemeral+: { volumeClaimTemplate+: { spec+: { volumeMode: volumeMode } } } },
              '#withVolumeName':: d.fn(help='"volumeName is the binding reference to the PersistentVolume backing this claim."', args=[d.arg(name='volumeName', type=d.T.string)]),
              withVolumeName(volumeName): { ephemeral+: { volumeClaimTemplate+: { spec+: { volumeName: volumeName } } } },
            },
            '#withMetadata':: d.fn(help='"May contain labels and annotations that will be copied into the PVC\\nwhen creating it. No other fields are allowed and will be rejected during\\nvalidation."', args=[d.arg(name='metadata', type=d.T.object)]),
            withMetadata(metadata): { ephemeral+: { volumeClaimTemplate+: { metadata: metadata } } },
            '#withMetadataMixin':: d.fn(help='"May contain labels and annotations that will be copied into the PVC\\nwhen creating it. No other fields are allowed and will be rejected during\\nvalidation."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='metadata', type=d.T.object)]),
            withMetadataMixin(metadata): { ephemeral+: { volumeClaimTemplate+: { metadata+: metadata } } },
          },
        },
        '#fc':: d.obj(help="\"fc represents a Fibre Channel resource that is attached to a kubelet's host machine and then exposed to the pod.\""),
        fc: {
          '#withFsType':: d.fn(help='"fsType is the filesystem type to mount.\\nMust be a filesystem type supported by the host operating system.\\nEx. \\"ext4\\", \\"xfs\\", \\"ntfs\\". Implicitly inferred to be \\"ext4\\" if unspecified.\\nTODO: how do we prevent errors in the filesystem from compromising the machine"', args=[d.arg(name='fsType', type=d.T.string)]),
          withFsType(fsType): { fc+: { fsType: fsType } },
          '#withLun':: d.fn(help='"lun is Optional: FC target lun number"', args=[d.arg(name='lun', type=d.T.integer)]),
          withLun(lun): { fc+: { lun: lun } },
          '#withReadOnly':: d.fn(help='"readOnly is Optional: Defaults to false (read/write). ReadOnly here will force\\nthe ReadOnly setting in VolumeMounts."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
          withReadOnly(readOnly): { fc+: { readOnly: readOnly } },
          '#withTargetWWNs':: d.fn(help='"targetWWNs is Optional: FC target worldwide names (WWNs)"', args=[d.arg(name='targetWWNs', type=d.T.array)]),
          withTargetWWNs(targetWWNs): { fc+: { targetWWNs: if std.isArray(v=targetWWNs) then targetWWNs else [targetWWNs] } },
          '#withTargetWWNsMixin':: d.fn(help='"targetWWNs is Optional: FC target worldwide names (WWNs)"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='targetWWNs', type=d.T.array)]),
          withTargetWWNsMixin(targetWWNs): { fc+: { targetWWNs+: if std.isArray(v=targetWWNs) then targetWWNs else [targetWWNs] } },
          '#withWwids':: d.fn(help='"wwids Optional: FC volume world wide identifiers (wwids)\\nEither wwids or combination of targetWWNs and lun must be set, but not both simultaneously."', args=[d.arg(name='wwids', type=d.T.array)]),
          withWwids(wwids): { fc+: { wwids: if std.isArray(v=wwids) then wwids else [wwids] } },
          '#withWwidsMixin':: d.fn(help='"wwids Optional: FC volume world wide identifiers (wwids)\\nEither wwids or combination of targetWWNs and lun must be set, but not both simultaneously."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='wwids', type=d.T.array)]),
          withWwidsMixin(wwids): { fc+: { wwids+: if std.isArray(v=wwids) then wwids else [wwids] } },
        },
        '#flexVolume':: d.obj(help='"flexVolume represents a generic volume resource that is\\nprovisioned/attached using an exec based plugin."'),
        flexVolume: {
          '#secretRef':: d.obj(help='"secretRef is Optional: secretRef is reference to the secret object containing\\nsensitive information to pass to the plugin scripts. This may be\\nempty if no secret object is specified. If the secret object\\ncontains more than one secret, all secrets are passed to the plugin\\nscripts."'),
          secretRef: {
            '#withName':: d.fn(help='"Name of the referent.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names\\nTODO: Add other useful fields. apiVersion, kind, uid?"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { flexVolume+: { secretRef+: { name: name } } },
          },
          '#withDriver':: d.fn(help='"driver is the name of the driver to use for this volume."', args=[d.arg(name='driver', type=d.T.string)]),
          withDriver(driver): { flexVolume+: { driver: driver } },
          '#withFsType':: d.fn(help='"fsType is the filesystem type to mount.\\nMust be a filesystem type supported by the host operating system.\\nEx. \\"ext4\\", \\"xfs\\", \\"ntfs\\". The default filesystem depends on FlexVolume script."', args=[d.arg(name='fsType', type=d.T.string)]),
          withFsType(fsType): { flexVolume+: { fsType: fsType } },
          '#withOptions':: d.fn(help='"options is Optional: this field holds extra command options if any."', args=[d.arg(name='options', type=d.T.object)]),
          withOptions(options): { flexVolume+: { options: options } },
          '#withOptionsMixin':: d.fn(help='"options is Optional: this field holds extra command options if any."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='options', type=d.T.object)]),
          withOptionsMixin(options): { flexVolume+: { options+: options } },
          '#withReadOnly':: d.fn(help='"readOnly is Optional: defaults to false (read/write). ReadOnly here will force\\nthe ReadOnly setting in VolumeMounts."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
          withReadOnly(readOnly): { flexVolume+: { readOnly: readOnly } },
        },
        '#flocker':: d.obj(help="\"flocker represents a Flocker volume attached to a kubelet's host machine. This depends on the Flocker control service being running\""),
        flocker: {
          '#withDatasetName':: d.fn(help='"datasetName is Name of the dataset stored as metadata -> name on the dataset for Flocker\\nshould be considered as deprecated"', args=[d.arg(name='datasetName', type=d.T.string)]),
          withDatasetName(datasetName): { flocker+: { datasetName: datasetName } },
          '#withDatasetUUID':: d.fn(help='"datasetUUID is the UUID of the dataset. This is unique identifier of a Flocker dataset"', args=[d.arg(name='datasetUUID', type=d.T.string)]),
          withDatasetUUID(datasetUUID): { flocker+: { datasetUUID: datasetUUID } },
        },
        '#gcePersistentDisk':: d.obj(help="\"gcePersistentDisk represents a GCE Disk resource that is attached to a\\nkubelet's host machine and then exposed to the pod.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk\""),
        gcePersistentDisk: {
          '#withFsType':: d.fn(help='"fsType is filesystem type of the volume that you want to mount.\\nTip: Ensure that the filesystem type is supported by the host operating system.\\nExamples: \\"ext4\\", \\"xfs\\", \\"ntfs\\". Implicitly inferred to be \\"ext4\\" if unspecified.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk\\nTODO: how do we prevent errors in the filesystem from compromising the machine"', args=[d.arg(name='fsType', type=d.T.string)]),
          withFsType(fsType): { gcePersistentDisk+: { fsType: fsType } },
          '#withPartition':: d.fn(help='"partition is the partition in the volume that you want to mount.\\nIf omitted, the default is to mount by volume name.\\nExamples: For volume /dev/sda1, you specify the partition as \\"1\\".\\nSimilarly, the volume partition for /dev/sda is \\"0\\" (or you can leave the property empty).\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk"', args=[d.arg(name='partition', type=d.T.integer)]),
          withPartition(partition): { gcePersistentDisk+: { partition: partition } },
          '#withPdName':: d.fn(help='"pdName is unique name of the PD resource in GCE. Used to identify the disk in GCE.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk"', args=[d.arg(name='pdName', type=d.T.string)]),
          withPdName(pdName): { gcePersistentDisk+: { pdName: pdName } },
          '#withReadOnly':: d.fn(help='"readOnly here will force the ReadOnly setting in VolumeMounts.\\nDefaults to false.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk"', args=[d.arg(name='readOnly', type=d.T.boolean)]),
          withReadOnly(readOnly): { gcePersistentDisk+: { readOnly: readOnly } },
        },
        '#gitRepo':: d.obj(help="\"gitRepo represents a git repository at a particular revision.\\nDEPRECATED: GitRepo is deprecated. To provision a container with a git repo, mount an\\nEmptyDir into an InitContainer that clones the repo using git, then mount the EmptyDir\\ninto the Pod's container.\""),
        gitRepo: {
          '#withDirectory':: d.fn(help="\"directory is the target directory name.\\nMust not contain or start with '..'.  If '.' is supplied, the volume directory will be the\\ngit repository.  Otherwise, if specified, the volume will contain the git repository in\\nthe subdirectory with the given name.\"", args=[d.arg(name='directory', type=d.T.string)]),
          withDirectory(directory): { gitRepo+: { directory: directory } },
          '#withRepository':: d.fn(help='"repository is the URL"', args=[d.arg(name='repository', type=d.T.string)]),
          withRepository(repository): { gitRepo+: { repository: repository } },
          '#withRevision':: d.fn(help='"revision is the commit hash for the specified revision."', args=[d.arg(name='revision', type=d.T.string)]),
          withRevision(revision): { gitRepo+: { revision: revision } },
        },
        '#glusterfs':: d.obj(help="\"glusterfs represents a Glusterfs mount on the host that shares a pod's lifetime.\\nMore info: https://examples.k8s.io/volumes/glusterfs/README.md\""),
        glusterfs: {
          '#withEndpoints':: d.fn(help='"endpoints is the endpoint name that details Glusterfs topology.\\nMore info: https://examples.k8s.io/volumes/glusterfs/README.md#create-a-pod"', args=[d.arg(name='endpoints', type=d.T.string)]),
          withEndpoints(endpoints): { glusterfs+: { endpoints: endpoints } },
          '#withPath':: d.fn(help='"path is the Glusterfs volume path.\\nMore info: https://examples.k8s.io/volumes/glusterfs/README.md#create-a-pod"', args=[d.arg(name='path', type=d.T.string)]),
          withPath(path): { glusterfs+: { path: path } },
          '#withReadOnly':: d.fn(help='"readOnly here will force the Glusterfs volume to be mounted with read-only permissions.\\nDefaults to false.\\nMore info: https://examples.k8s.io/volumes/glusterfs/README.md#create-a-pod"', args=[d.arg(name='readOnly', type=d.T.boolean)]),
          withReadOnly(readOnly): { glusterfs+: { readOnly: readOnly } },
        },
        '#hostPath':: d.obj(help='"hostPath represents a pre-existing file or directory on the host\\nmachine that is directly exposed to the container. This is generally\\nused for system agents or other privileged things that are allowed\\nto see the host machine. Most containers will NOT need this.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath\\n---\\nTODO(jonesdl) We need to restrict who can use host directory mounts and who can/can not\\nmount host directories as read/write."'),
        hostPath: {
          '#withPath':: d.fn(help='"path of the directory on the host.\\nIf the path is a symlink, it will follow the link to the real path.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath"', args=[d.arg(name='path', type=d.T.string)]),
          withPath(path): { hostPath+: { path: path } },
          '#withType':: d.fn(help='"type for HostPath Volume\\nDefaults to \\"\\"\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath"', args=[d.arg(name='type', type=d.T.string)]),
          withType(type): { hostPath+: { type: type } },
        },
        '#iscsi':: d.obj(help="\"iscsi represents an ISCSI Disk resource that is attached to a\\nkubelet's host machine and then exposed to the pod.\\nMore info: https://examples.k8s.io/volumes/iscsi/README.md\""),
        iscsi: {
          '#secretRef':: d.obj(help='"secretRef is the CHAP Secret for iSCSI target and initiator authentication"'),
          secretRef: {
            '#withName':: d.fn(help='"Name of the referent.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names\\nTODO: Add other useful fields. apiVersion, kind, uid?"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { iscsi+: { secretRef+: { name: name } } },
          },
          '#withChapAuthDiscovery':: d.fn(help='"chapAuthDiscovery defines whether support iSCSI Discovery CHAP authentication"', args=[d.arg(name='chapAuthDiscovery', type=d.T.boolean)]),
          withChapAuthDiscovery(chapAuthDiscovery): { iscsi+: { chapAuthDiscovery: chapAuthDiscovery } },
          '#withChapAuthSession':: d.fn(help='"chapAuthSession defines whether support iSCSI Session CHAP authentication"', args=[d.arg(name='chapAuthSession', type=d.T.boolean)]),
          withChapAuthSession(chapAuthSession): { iscsi+: { chapAuthSession: chapAuthSession } },
          '#withFsType':: d.fn(help='"fsType is the filesystem type of the volume that you want to mount.\\nTip: Ensure that the filesystem type is supported by the host operating system.\\nExamples: \\"ext4\\", \\"xfs\\", \\"ntfs\\". Implicitly inferred to be \\"ext4\\" if unspecified.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#iscsi\\nTODO: how do we prevent errors in the filesystem from compromising the machine"', args=[d.arg(name='fsType', type=d.T.string)]),
          withFsType(fsType): { iscsi+: { fsType: fsType } },
          '#withInitiatorName':: d.fn(help='"initiatorName is the custom iSCSI Initiator Name.\\nIf initiatorName is specified with iscsiInterface simultaneously, new iSCSI interface\\n<target portal>:<volume name> will be created for the connection."', args=[d.arg(name='initiatorName', type=d.T.string)]),
          withInitiatorName(initiatorName): { iscsi+: { initiatorName: initiatorName } },
          '#withIqn':: d.fn(help='"iqn is the target iSCSI Qualified Name."', args=[d.arg(name='iqn', type=d.T.string)]),
          withIqn(iqn): { iscsi+: { iqn: iqn } },
          '#withIscsiInterface':: d.fn(help="\"iscsiInterface is the interface Name that uses an iSCSI transport.\\nDefaults to 'default' (tcp).\"", args=[d.arg(name='iscsiInterface', type=d.T.string)]),
          withIscsiInterface(iscsiInterface): { iscsi+: { iscsiInterface: iscsiInterface } },
          '#withLun':: d.fn(help='"lun represents iSCSI Target Lun number."', args=[d.arg(name='lun', type=d.T.integer)]),
          withLun(lun): { iscsi+: { lun: lun } },
          '#withPortals':: d.fn(help='"portals is the iSCSI Target Portal List. The portal is either an IP or ip_addr:port if the port\\nis other than default (typically TCP ports 860 and 3260)."', args=[d.arg(name='portals', type=d.T.array)]),
          withPortals(portals): { iscsi+: { portals: if std.isArray(v=portals) then portals else [portals] } },
          '#withPortalsMixin':: d.fn(help='"portals is the iSCSI Target Portal List. The portal is either an IP or ip_addr:port if the port\\nis other than default (typically TCP ports 860 and 3260)."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='portals', type=d.T.array)]),
          withPortalsMixin(portals): { iscsi+: { portals+: if std.isArray(v=portals) then portals else [portals] } },
          '#withReadOnly':: d.fn(help='"readOnly here will force the ReadOnly setting in VolumeMounts.\\nDefaults to false."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
          withReadOnly(readOnly): { iscsi+: { readOnly: readOnly } },
          '#withTargetPortal':: d.fn(help='"targetPortal is iSCSI Target Portal. The Portal is either an IP or ip_addr:port if the port\\nis other than default (typically TCP ports 860 and 3260)."', args=[d.arg(name='targetPortal', type=d.T.string)]),
          withTargetPortal(targetPortal): { iscsi+: { targetPortal: targetPortal } },
        },
        '#nfs':: d.obj(help="\"nfs represents an NFS mount on the host that shares a pod's lifetime\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#nfs\""),
        nfs: {
          '#withPath':: d.fn(help='"path that is exported by the NFS server.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#nfs"', args=[d.arg(name='path', type=d.T.string)]),
          withPath(path): { nfs+: { path: path } },
          '#withReadOnly':: d.fn(help='"readOnly here will force the NFS export to be mounted with read-only permissions.\\nDefaults to false.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#nfs"', args=[d.arg(name='readOnly', type=d.T.boolean)]),
          withReadOnly(readOnly): { nfs+: { readOnly: readOnly } },
          '#withServer':: d.fn(help='"server is the hostname or IP address of the NFS server.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#nfs"', args=[d.arg(name='server', type=d.T.string)]),
          withServer(server): { nfs+: { server: server } },
        },
        '#persistentVolumeClaim':: d.obj(help='"persistentVolumeClaimVolumeSource represents a reference to a\\nPersistentVolumeClaim in the same namespace.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims"'),
        persistentVolumeClaim: {
          '#withClaimName':: d.fn(help='"claimName is the name of a PersistentVolumeClaim in the same namespace as the pod using this volume.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims"', args=[d.arg(name='claimName', type=d.T.string)]),
          withClaimName(claimName): { persistentVolumeClaim+: { claimName: claimName } },
          '#withReadOnly':: d.fn(help='"readOnly Will force the ReadOnly setting in VolumeMounts.\\nDefault false."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
          withReadOnly(readOnly): { persistentVolumeClaim+: { readOnly: readOnly } },
        },
        '#photonPersistentDisk':: d.obj(help='"photonPersistentDisk represents a PhotonController persistent disk attached and mounted on kubelets host machine"'),
        photonPersistentDisk: {
          '#withFsType':: d.fn(help='"fsType is the filesystem type to mount.\\nMust be a filesystem type supported by the host operating system.\\nEx. \\"ext4\\", \\"xfs\\", \\"ntfs\\". Implicitly inferred to be \\"ext4\\" if unspecified."', args=[d.arg(name='fsType', type=d.T.string)]),
          withFsType(fsType): { photonPersistentDisk+: { fsType: fsType } },
          '#withPdID':: d.fn(help='"pdID is the ID that identifies Photon Controller persistent disk"', args=[d.arg(name='pdID', type=d.T.string)]),
          withPdID(pdID): { photonPersistentDisk+: { pdID: pdID } },
        },
        '#portworxVolume':: d.obj(help='"portworxVolume represents a portworx volume attached and mounted on kubelets host machine"'),
        portworxVolume: {
          '#withFsType':: d.fn(help='"fSType represents the filesystem type to mount\\nMust be a filesystem type supported by the host operating system.\\nEx. \\"ext4\\", \\"xfs\\". Implicitly inferred to be \\"ext4\\" if unspecified."', args=[d.arg(name='fsType', type=d.T.string)]),
          withFsType(fsType): { portworxVolume+: { fsType: fsType } },
          '#withReadOnly':: d.fn(help='"readOnly defaults to false (read/write). ReadOnly here will force\\nthe ReadOnly setting in VolumeMounts."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
          withReadOnly(readOnly): { portworxVolume+: { readOnly: readOnly } },
          '#withVolumeID':: d.fn(help='"volumeID uniquely identifies a Portworx volume"', args=[d.arg(name='volumeID', type=d.T.string)]),
          withVolumeID(volumeID): { portworxVolume+: { volumeID: volumeID } },
        },
        '#projected':: d.obj(help='"projected items for all in one resources secrets, configmaps, and downward API"'),
        projected: {
          '#sources':: d.obj(help='"sources is the list of volume projections"'),
          sources: {
            '#clusterTrustBundle':: d.obj(help='"ClusterTrustBundle allows a pod to access the `.spec.trustBundle` field\\nof ClusterTrustBundle objects in an auto-updating file.\\nAlpha, gated by the ClusterTrustBundleProjection feature gate.\\nClusterTrustBundle objects can either be selected by name, or by the\\ncombination of signer name and a label selector.\\nKubelet performs aggressive normalization of the PEM contents written\\ninto the pod filesystem.  Esoteric PEM features such as inter-block\\ncomments and block headers are stripped.  Certificates are deduplicated.\\nThe ordering of certificates within the file is arbitrary, and Kubelet\\nmay change the order over time."'),
            clusterTrustBundle: {
              '#labelSelector':: d.obj(help='"Select all ClusterTrustBundles that match this label selector.  Only has\\neffect if signerName is set.  Mutually-exclusive with name.  If unset,\\ninterpreted as \\"match nothing\\".  If set but empty, interpreted as \\"match\\neverything\\"."'),
              labelSelector: {
                '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                matchExpressions: {
                  '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { clusterTrustBundle+: { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { clusterTrustBundle+: { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabels(matchLabels): { clusterTrustBundle+: { labelSelector+: { matchLabels: matchLabels } } },
                '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabelsMixin(matchLabels): { clusterTrustBundle+: { labelSelector+: { matchLabels+: matchLabels } } },
              },
              '#withName':: d.fn(help='"Select a single ClusterTrustBundle by object name.  Mutually-exclusive\\nwith signerName and labelSelector."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { clusterTrustBundle+: { name: name } },
              '#withOptional':: d.fn(help="\"If true, don't block pod startup if the referenced ClusterTrustBundle(s)\\naren't available.  If using name, then the named ClusterTrustBundle is\\nallowed not to exist.  If using signerName, then the combination of\\nsignerName and labelSelector is allowed to match zero\\nClusterTrustBundles.\"", args=[d.arg(name='optional', type=d.T.boolean)]),
              withOptional(optional): { clusterTrustBundle+: { optional: optional } },
              '#withPath':: d.fn(help='"Relative path from the volume root to write the bundle."', args=[d.arg(name='path', type=d.T.string)]),
              withPath(path): { clusterTrustBundle+: { path: path } },
              '#withSignerName':: d.fn(help='"Select all ClusterTrustBundles that match this signer name.\\nMutually-exclusive with name.  The contents of all selected\\nClusterTrustBundles will be unified and deduplicated."', args=[d.arg(name='signerName', type=d.T.string)]),
              withSignerName(signerName): { clusterTrustBundle+: { signerName: signerName } },
            },
            '#configMap':: d.obj(help='"configMap information about the configMap data to project"'),
            configMap: {
              '#items':: d.obj(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nConfigMap will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the ConfigMap,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\""),
              items: {
                '#withKey':: d.fn(help='"key is the key to project."', args=[d.arg(name='key', type=d.T.string)]),
                withKey(key): { key: key },
                '#withMode':: d.fn(help='"mode is Optional: mode bits used to set permissions on this file.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
                withMode(mode): { mode: mode },
                '#withPath':: d.fn(help="\"path is the relative path of the file to map the key to.\\nMay not be an absolute path.\\nMay not contain the path element '..'.\\nMay not start with the string '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
                withPath(path): { path: path },
              },
              '#withItems':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nConfigMap will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the ConfigMap,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"", args=[d.arg(name='items', type=d.T.array)]),
              withItems(items): { configMap+: { items: if std.isArray(v=items) then items else [items] } },
              '#withItemsMixin':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nConfigMap will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the ConfigMap,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='items', type=d.T.array)]),
              withItemsMixin(items): { configMap+: { items+: if std.isArray(v=items) then items else [items] } },
              '#withName':: d.fn(help='"Name of the referent.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names\\nTODO: Add other useful fields. apiVersion, kind, uid?"', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { configMap+: { name: name } },
              '#withOptional':: d.fn(help='"optional specify whether the ConfigMap or its keys must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
              withOptional(optional): { configMap+: { optional: optional } },
            },
            '#downwardAPI':: d.obj(help='"downwardAPI information about the downwardAPI data to project"'),
            downwardAPI: {
              '#items':: d.obj(help='"Items is a list of DownwardAPIVolume file"'),
              items: {
                '#fieldRef':: d.obj(help='"Required: Selects a field of the pod: only annotations, labels, name and namespace are supported."'),
                fieldRef: {
                  '#withApiVersion':: d.fn(help='"Version of the schema the FieldPath is written in terms of, defaults to \\"v1\\"."', args=[d.arg(name='apiVersion', type=d.T.string)]),
                  withApiVersion(apiVersion): { fieldRef+: { apiVersion: apiVersion } },
                  '#withFieldPath':: d.fn(help='"Path of the field to select in the specified API version."', args=[d.arg(name='fieldPath', type=d.T.string)]),
                  withFieldPath(fieldPath): { fieldRef+: { fieldPath: fieldPath } },
                },
                '#resourceFieldRef':: d.obj(help='"Selects a resource of the container: only resources limits and requests\\n(limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported."'),
                resourceFieldRef: {
                  '#withContainerName':: d.fn(help='"Container name: required for volumes, optional for env vars"', args=[d.arg(name='containerName', type=d.T.string)]),
                  withContainerName(containerName): { resourceFieldRef+: { containerName: containerName } },
                  '#withDivisor':: d.fn(help='"Specifies the output format of the exposed resources, defaults to \\"1\\', args=[d.arg(name='divisor', type=d.T.any)]),
                  withDivisor(divisor): { resourceFieldRef+: { divisor: divisor } },
                  '#withResource':: d.fn(help='"Required: resource to select"', args=[d.arg(name='resource', type=d.T.string)]),
                  withResource(resource): { resourceFieldRef+: { resource: resource } },
                },
                '#withMode':: d.fn(help='"Optional: mode bits used to set permissions on this file, must be an octal value\\nbetween 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
                withMode(mode): { mode: mode },
                '#withPath':: d.fn(help="\"Required: Path is  the relative path name of the file to be created. Must not be absolute or contain the '..' path. Must be utf-8 encoded. The first item of the relative path must not start with '..'\"", args=[d.arg(name='path', type=d.T.string)]),
                withPath(path): { path: path },
              },
              '#withItems':: d.fn(help='"Items is a list of DownwardAPIVolume file"', args=[d.arg(name='items', type=d.T.array)]),
              withItems(items): { downwardAPI+: { items: if std.isArray(v=items) then items else [items] } },
              '#withItemsMixin':: d.fn(help='"Items is a list of DownwardAPIVolume file"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='items', type=d.T.array)]),
              withItemsMixin(items): { downwardAPI+: { items+: if std.isArray(v=items) then items else [items] } },
            },
            '#secret':: d.obj(help='"secret information about the secret data to project"'),
            secret: {
              '#items':: d.obj(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\""),
              items: {
                '#withKey':: d.fn(help='"key is the key to project."', args=[d.arg(name='key', type=d.T.string)]),
                withKey(key): { key: key },
                '#withMode':: d.fn(help='"mode is Optional: mode bits used to set permissions on this file.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
                withMode(mode): { mode: mode },
                '#withPath':: d.fn(help="\"path is the relative path of the file to map the key to.\\nMay not be an absolute path.\\nMay not contain the path element '..'.\\nMay not start with the string '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
                withPath(path): { path: path },
              },
              '#withItems':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"", args=[d.arg(name='items', type=d.T.array)]),
              withItems(items): { secret+: { items: if std.isArray(v=items) then items else [items] } },
              '#withItemsMixin':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='items', type=d.T.array)]),
              withItemsMixin(items): { secret+: { items+: if std.isArray(v=items) then items else [items] } },
              '#withName':: d.fn(help='"Name of the referent.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names\\nTODO: Add other useful fields. apiVersion, kind, uid?"', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { secret+: { name: name } },
              '#withOptional':: d.fn(help='"optional field specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
              withOptional(optional): { secret+: { optional: optional } },
            },
            '#serviceAccountToken':: d.obj(help='"serviceAccountToken is information about the serviceAccountToken data to project"'),
            serviceAccountToken: {
              '#withAudience':: d.fn(help='"audience is the intended audience of the token. A recipient of a token\\nmust identify itself with an identifier specified in the audience of the\\ntoken, and otherwise should reject the token. The audience defaults to the\\nidentifier of the apiserver."', args=[d.arg(name='audience', type=d.T.string)]),
              withAudience(audience): { serviceAccountToken+: { audience: audience } },
              '#withExpirationSeconds':: d.fn(help='"expirationSeconds is the requested duration of validity of the service\\naccount token. As the token approaches expiration, the kubelet volume\\nplugin will proactively rotate the service account token. The kubelet will\\nstart trying to rotate the token if the token is older than 80 percent of\\nits time to live or if the token is older than 24 hours.Defaults to 1 hour\\nand must be at least 10 minutes."', args=[d.arg(name='expirationSeconds', type=d.T.integer)]),
              withExpirationSeconds(expirationSeconds): { serviceAccountToken+: { expirationSeconds: expirationSeconds } },
              '#withPath':: d.fn(help='"path is the path relative to the mount point of the file to project the\\ntoken into."', args=[d.arg(name='path', type=d.T.string)]),
              withPath(path): { serviceAccountToken+: { path: path } },
            },
          },
          '#withDefaultMode':: d.fn(help='"defaultMode are the mode bits used to set permissions on created files by default.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nDirectories within the path are not affected by this setting.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='defaultMode', type=d.T.integer)]),
          withDefaultMode(defaultMode): { projected+: { defaultMode: defaultMode } },
          '#withSources':: d.fn(help='"sources is the list of volume projections"', args=[d.arg(name='sources', type=d.T.array)]),
          withSources(sources): { projected+: { sources: if std.isArray(v=sources) then sources else [sources] } },
          '#withSourcesMixin':: d.fn(help='"sources is the list of volume projections"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='sources', type=d.T.array)]),
          withSourcesMixin(sources): { projected+: { sources+: if std.isArray(v=sources) then sources else [sources] } },
        },
        '#quobyte':: d.obj(help="\"quobyte represents a Quobyte mount on the host that shares a pod's lifetime\""),
        quobyte: {
          '#withGroup':: d.fn(help='"group to map volume access to\\nDefault is no group"', args=[d.arg(name='group', type=d.T.string)]),
          withGroup(group): { quobyte+: { group: group } },
          '#withReadOnly':: d.fn(help='"readOnly here will force the Quobyte volume to be mounted with read-only permissions.\\nDefaults to false."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
          withReadOnly(readOnly): { quobyte+: { readOnly: readOnly } },
          '#withRegistry':: d.fn(help='"registry represents a single or multiple Quobyte Registry services\\nspecified as a string as host:port pair (multiple entries are separated with commas)\\nwhich acts as the central registry for volumes"', args=[d.arg(name='registry', type=d.T.string)]),
          withRegistry(registry): { quobyte+: { registry: registry } },
          '#withTenant':: d.fn(help='"tenant owning the given Quobyte volume in the Backend\\nUsed with dynamically provisioned Quobyte volumes, value is set by the plugin"', args=[d.arg(name='tenant', type=d.T.string)]),
          withTenant(tenant): { quobyte+: { tenant: tenant } },
          '#withUser':: d.fn(help='"user to map volume access to\\nDefaults to serivceaccount user"', args=[d.arg(name='user', type=d.T.string)]),
          withUser(user): { quobyte+: { user: user } },
          '#withVolume':: d.fn(help='"volume is a string that references an already created Quobyte volume by name."', args=[d.arg(name='volume', type=d.T.string)]),
          withVolume(volume): { quobyte+: { volume: volume } },
        },
        '#rbd':: d.obj(help="\"rbd represents a Rados Block Device mount on the host that shares a pod's lifetime.\\nMore info: https://examples.k8s.io/volumes/rbd/README.md\""),
        rbd: {
          '#secretRef':: d.obj(help='"secretRef is name of the authentication secret for RBDUser. If provided\\noverrides keyring.\\nDefault is nil.\\nMore info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it"'),
          secretRef: {
            '#withName':: d.fn(help='"Name of the referent.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names\\nTODO: Add other useful fields. apiVersion, kind, uid?"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { rbd+: { secretRef+: { name: name } } },
          },
          '#withFsType':: d.fn(help='"fsType is the filesystem type of the volume that you want to mount.\\nTip: Ensure that the filesystem type is supported by the host operating system.\\nExamples: \\"ext4\\", \\"xfs\\", \\"ntfs\\". Implicitly inferred to be \\"ext4\\" if unspecified.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#rbd\\nTODO: how do we prevent errors in the filesystem from compromising the machine"', args=[d.arg(name='fsType', type=d.T.string)]),
          withFsType(fsType): { rbd+: { fsType: fsType } },
          '#withImage':: d.fn(help='"image is the rados image name.\\nMore info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it"', args=[d.arg(name='image', type=d.T.string)]),
          withImage(image): { rbd+: { image: image } },
          '#withKeyring':: d.fn(help='"keyring is the path to key ring for RBDUser.\\nDefault is /etc/ceph/keyring.\\nMore info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it"', args=[d.arg(name='keyring', type=d.T.string)]),
          withKeyring(keyring): { rbd+: { keyring: keyring } },
          '#withMonitors':: d.fn(help='"monitors is a collection of Ceph monitors.\\nMore info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it"', args=[d.arg(name='monitors', type=d.T.array)]),
          withMonitors(monitors): { rbd+: { monitors: if std.isArray(v=monitors) then monitors else [monitors] } },
          '#withMonitorsMixin':: d.fn(help='"monitors is a collection of Ceph monitors.\\nMore info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='monitors', type=d.T.array)]),
          withMonitorsMixin(monitors): { rbd+: { monitors+: if std.isArray(v=monitors) then monitors else [monitors] } },
          '#withPool':: d.fn(help='"pool is the rados pool name.\\nDefault is rbd.\\nMore info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it"', args=[d.arg(name='pool', type=d.T.string)]),
          withPool(pool): { rbd+: { pool: pool } },
          '#withReadOnly':: d.fn(help='"readOnly here will force the ReadOnly setting in VolumeMounts.\\nDefaults to false.\\nMore info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it"', args=[d.arg(name='readOnly', type=d.T.boolean)]),
          withReadOnly(readOnly): { rbd+: { readOnly: readOnly } },
          '#withUser':: d.fn(help='"user is the rados user name.\\nDefault is admin.\\nMore info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it"', args=[d.arg(name='user', type=d.T.string)]),
          withUser(user): { rbd+: { user: user } },
        },
        '#scaleIO':: d.obj(help='"scaleIO represents a ScaleIO persistent volume attached and mounted on Kubernetes nodes."'),
        scaleIO: {
          '#secretRef':: d.obj(help='"secretRef references to the secret for ScaleIO user and other\\nsensitive information. If this is not provided, Login operation will fail."'),
          secretRef: {
            '#withName':: d.fn(help='"Name of the referent.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names\\nTODO: Add other useful fields. apiVersion, kind, uid?"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { scaleIO+: { secretRef+: { name: name } } },
          },
          '#withFsType':: d.fn(help='"fsType is the filesystem type to mount.\\nMust be a filesystem type supported by the host operating system.\\nEx. \\"ext4\\", \\"xfs\\", \\"ntfs\\".\\nDefault is \\"xfs\\"."', args=[d.arg(name='fsType', type=d.T.string)]),
          withFsType(fsType): { scaleIO+: { fsType: fsType } },
          '#withGateway':: d.fn(help='"gateway is the host address of the ScaleIO API Gateway."', args=[d.arg(name='gateway', type=d.T.string)]),
          withGateway(gateway): { scaleIO+: { gateway: gateway } },
          '#withProtectionDomain':: d.fn(help='"protectionDomain is the name of the ScaleIO Protection Domain for the configured storage."', args=[d.arg(name='protectionDomain', type=d.T.string)]),
          withProtectionDomain(protectionDomain): { scaleIO+: { protectionDomain: protectionDomain } },
          '#withReadOnly':: d.fn(help='"readOnly Defaults to false (read/write). ReadOnly here will force\\nthe ReadOnly setting in VolumeMounts."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
          withReadOnly(readOnly): { scaleIO+: { readOnly: readOnly } },
          '#withSslEnabled':: d.fn(help='"sslEnabled Flag enable/disable SSL communication with Gateway, default false"', args=[d.arg(name='sslEnabled', type=d.T.boolean)]),
          withSslEnabled(sslEnabled): { scaleIO+: { sslEnabled: sslEnabled } },
          '#withStorageMode':: d.fn(help='"storageMode indicates whether the storage for a volume should be ThickProvisioned or ThinProvisioned.\\nDefault is ThinProvisioned."', args=[d.arg(name='storageMode', type=d.T.string)]),
          withStorageMode(storageMode): { scaleIO+: { storageMode: storageMode } },
          '#withStoragePool':: d.fn(help='"storagePool is the ScaleIO Storage Pool associated with the protection domain."', args=[d.arg(name='storagePool', type=d.T.string)]),
          withStoragePool(storagePool): { scaleIO+: { storagePool: storagePool } },
          '#withSystem':: d.fn(help='"system is the name of the storage system as configured in ScaleIO."', args=[d.arg(name='system', type=d.T.string)]),
          withSystem(system): { scaleIO+: { system: system } },
          '#withVolumeName':: d.fn(help='"volumeName is the name of a volume already created in the ScaleIO system\\nthat is associated with this volume source."', args=[d.arg(name='volumeName', type=d.T.string)]),
          withVolumeName(volumeName): { scaleIO+: { volumeName: volumeName } },
        },
        '#secret':: d.obj(help='"secret represents a secret that should populate this volume.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#secret"'),
        secret: {
          '#items':: d.obj(help="\"items If unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\""),
          items: {
            '#withKey':: d.fn(help='"key is the key to project."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { key: key },
            '#withMode':: d.fn(help='"mode is Optional: mode bits used to set permissions on this file.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
            withMode(mode): { mode: mode },
            '#withPath':: d.fn(help="\"path is the relative path of the file to map the key to.\\nMay not be an absolute path.\\nMay not contain the path element '..'.\\nMay not start with the string '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
            withPath(path): { path: path },
          },
          '#withDefaultMode':: d.fn(help='"defaultMode is Optional: mode bits used to set permissions on created files by default.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values\\nfor mode bits. Defaults to 0644.\\nDirectories within the path are not affected by this setting.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='defaultMode', type=d.T.integer)]),
          withDefaultMode(defaultMode): { secret+: { defaultMode: defaultMode } },
          '#withItems':: d.fn(help="\"items If unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"", args=[d.arg(name='items', type=d.T.array)]),
          withItems(items): { secret+: { items: if std.isArray(v=items) then items else [items] } },
          '#withItemsMixin':: d.fn(help="\"items If unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='items', type=d.T.array)]),
          withItemsMixin(items): { secret+: { items+: if std.isArray(v=items) then items else [items] } },
          '#withOptional':: d.fn(help='"optional field specify whether the Secret or its keys must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
          withOptional(optional): { secret+: { optional: optional } },
          '#withSecretName':: d.fn(help="\"secretName is the name of the secret in the pod's namespace to use.\\nMore info: https://kubernetes.io/docs/concepts/storage/volumes#secret\"", args=[d.arg(name='secretName', type=d.T.string)]),
          withSecretName(secretName): { secret+: { secretName: secretName } },
        },
        '#storageos':: d.obj(help='"storageOS represents a StorageOS volume attached and mounted on Kubernetes nodes."'),
        storageos: {
          '#secretRef':: d.obj(help='"secretRef specifies the secret to use for obtaining the StorageOS API\\ncredentials.  If not specified, default values will be attempted."'),
          secretRef: {
            '#withName':: d.fn(help='"Name of the referent.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names\\nTODO: Add other useful fields. apiVersion, kind, uid?"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { storageos+: { secretRef+: { name: name } } },
          },
          '#withFsType':: d.fn(help='"fsType is the filesystem type to mount.\\nMust be a filesystem type supported by the host operating system.\\nEx. \\"ext4\\", \\"xfs\\", \\"ntfs\\". Implicitly inferred to be \\"ext4\\" if unspecified."', args=[d.arg(name='fsType', type=d.T.string)]),
          withFsType(fsType): { storageos+: { fsType: fsType } },
          '#withReadOnly':: d.fn(help='"readOnly defaults to false (read/write). ReadOnly here will force\\nthe ReadOnly setting in VolumeMounts."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
          withReadOnly(readOnly): { storageos+: { readOnly: readOnly } },
          '#withVolumeName':: d.fn(help='"volumeName is the human-readable name of the StorageOS volume.  Volume\\nnames are only unique within a namespace."', args=[d.arg(name='volumeName', type=d.T.string)]),
          withVolumeName(volumeName): { storageos+: { volumeName: volumeName } },
          '#withVolumeNamespace':: d.fn(help="\"volumeNamespace specifies the scope of the volume within StorageOS.  If no\\nnamespace is specified then the Pod's namespace will be used.  This allows the\\nKubernetes name scoping to be mirrored within StorageOS for tighter integration.\\nSet VolumeName to any name to override the default behaviour.\\nSet to \\\"default\\\" if you are not using namespaces within StorageOS.\\nNamespaces that do not pre-exist within StorageOS will be created.\"", args=[d.arg(name='volumeNamespace', type=d.T.string)]),
          withVolumeNamespace(volumeNamespace): { storageos+: { volumeNamespace: volumeNamespace } },
        },
        '#vsphereVolume':: d.obj(help='"vsphereVolume represents a vSphere volume attached and mounted on kubelets host machine"'),
        vsphereVolume: {
          '#withFsType':: d.fn(help='"fsType is filesystem type to mount.\\nMust be a filesystem type supported by the host operating system.\\nEx. \\"ext4\\", \\"xfs\\", \\"ntfs\\". Implicitly inferred to be \\"ext4\\" if unspecified."', args=[d.arg(name='fsType', type=d.T.string)]),
          withFsType(fsType): { vsphereVolume+: { fsType: fsType } },
          '#withStoragePolicyID':: d.fn(help='"storagePolicyID is the storage Policy Based Management (SPBM) profile ID associated with the StoragePolicyName."', args=[d.arg(name='storagePolicyID', type=d.T.string)]),
          withStoragePolicyID(storagePolicyID): { vsphereVolume+: { storagePolicyID: storagePolicyID } },
          '#withStoragePolicyName':: d.fn(help='"storagePolicyName is the storage Policy Based Management (SPBM) profile name."', args=[d.arg(name='storagePolicyName', type=d.T.string)]),
          withStoragePolicyName(storagePolicyName): { vsphereVolume+: { storagePolicyName: storagePolicyName } },
          '#withVolumePath':: d.fn(help='"volumePath is the path that identifies vSphere volume vmdk"', args=[d.arg(name='volumePath', type=d.T.string)]),
          withVolumePath(volumePath): { vsphereVolume+: { volumePath: volumePath } },
        },
        '#withName':: d.fn(help='"name of the volume.\\nMust be a DNS_LABEL and unique within the pod.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { name: name },
      },
      '#networkPublishing':: d.obj(help='"NetworkPublishing defines how to expose Envoy to a network."'),
      networkPublishing: {
        '#withExternalTrafficPolicy':: d.fn(help="\"ExternalTrafficPolicy describes how nodes distribute service traffic they\\nreceive on one of the Service's \\\"externally-facing\\\" addresses (NodePorts, ExternalIPs,\\nand LoadBalancer IPs).\\nIf unset, defaults to \\\"Local\\\".\"", args=[d.arg(name='externalTrafficPolicy', type=d.T.string)]),
        withExternalTrafficPolicy(externalTrafficPolicy): { spec+: { envoy+: { networkPublishing+: { externalTrafficPolicy: externalTrafficPolicy } } } },
        '#withIpFamilyPolicy':: d.fn(help='"IPFamilyPolicy represents the dual-stack-ness requested or required by\\nthis Service. If there is no value provided, then this field will be set\\nto SingleStack. Services can be \\"SingleStack\\" (a single IP family),\\n\\"PreferDualStack\\" (two IP families on dual-stack configured clusters or\\na single IP family on single-stack clusters), or \\"RequireDualStack\\"\\n(two IP families on dual-stack configured clusters, otherwise fail)."', args=[d.arg(name='ipFamilyPolicy', type=d.T.string)]),
        withIpFamilyPolicy(ipFamilyPolicy): { spec+: { envoy+: { networkPublishing+: { ipFamilyPolicy: ipFamilyPolicy } } } },
        '#withServiceAnnotations':: d.fn(help='"ServiceAnnotations is the annotations to add to\\nthe provisioned Envoy service."', args=[d.arg(name='serviceAnnotations', type=d.T.object)]),
        withServiceAnnotations(serviceAnnotations): { spec+: { envoy+: { networkPublishing+: { serviceAnnotations: serviceAnnotations } } } },
        '#withServiceAnnotationsMixin':: d.fn(help='"ServiceAnnotations is the annotations to add to\\nthe provisioned Envoy service."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='serviceAnnotations', type=d.T.object)]),
        withServiceAnnotationsMixin(serviceAnnotations): { spec+: { envoy+: { networkPublishing+: { serviceAnnotations+: serviceAnnotations } } } },
        '#withType':: d.fn(help="\"NetworkPublishingType is the type of publishing strategy to use. Valid values are:\\n* LoadBalancerService\\nIn this configuration, network endpoints for Envoy use container networking.\\nA Kubernetes LoadBalancer Service is created to publish Envoy network\\nendpoints.\\nSee: https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer\\n* NodePortService\\nPublishes Envoy network endpoints using a Kubernetes NodePort Service.\\nIn this configuration, Envoy network endpoints use container networking. A Kubernetes\\nNodePort Service is created to publish the network endpoints.\\nSee: https://kubernetes.io/docs/concepts/services-networking/service/#nodeport\\nNOTE:\\nWhen provisioning an Envoy `NodePortService`, use Gateway Listeners' port numbers to populate\\nthe Service's node port values, there's no way to auto-allocate them.\\nSee: https://github.com/projectcontour/contour/issues/4499\\n* ClusterIPService\\nPublishes Envoy network endpoints using a Kubernetes ClusterIP Service.\\nIn this configuration, Envoy network endpoints use container networking. A Kubernetes\\nClusterIP Service is created to publish the network endpoints.\\nSee: https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types\\nIf unset, defaults to LoadBalancerService.\"", args=[d.arg(name='type', type=d.T.string)]),
        withType(type): { spec+: { envoy+: { networkPublishing+: { type: type } } } },
      },
      '#nodePlacement':: d.obj(help='"NodePlacement describes node scheduling configuration of Envoy pods."'),
      nodePlacement: {
        '#tolerations':: d.obj(help='"Tolerations work with taints to ensure that pods are not scheduled\\nonto inappropriate nodes. One or more taints are applied to a node; this\\nmarks that the node should not accept any pods that do not tolerate the\\ntaints.\\nThe default is an empty list.\\nSee https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\\nfor additional details."'),
        tolerations: {
          '#withEffect':: d.fn(help='"Effect indicates the taint effect to match. Empty means match all taint effects.\\nWhen specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute."', args=[d.arg(name='effect', type=d.T.string)]),
          withEffect(effect): { effect: effect },
          '#withKey':: d.fn(help='"Key is the taint key that the toleration applies to. Empty means match all taint keys.\\nIf the key is empty, operator must be Exists; this combination means to match all values and all keys."', args=[d.arg(name='key', type=d.T.string)]),
          withKey(key): { key: key },
          '#withOperator':: d.fn(help="\"Operator represents a key's relationship to the value.\\nValid operators are Exists and Equal. Defaults to Equal.\\nExists is equivalent to wildcard for value, so that a pod can\\ntolerate all taints of a particular category.\"", args=[d.arg(name='operator', type=d.T.string)]),
          withOperator(operator): { operator: operator },
          '#withTolerationSeconds':: d.fn(help='"TolerationSeconds represents the period of time the toleration (which must be\\nof effect NoExecute, otherwise this field is ignored) tolerates the taint. By default,\\nit is not set, which means tolerate the taint forever (do not evict). Zero and\\nnegative values will be treated as 0 (evict immediately) by the system."', args=[d.arg(name='tolerationSeconds', type=d.T.integer)]),
          withTolerationSeconds(tolerationSeconds): { tolerationSeconds: tolerationSeconds },
          '#withValue':: d.fn(help='"Value is the taint value the toleration matches to.\\nIf the operator is Exists, the value should be empty, otherwise just a regular string."', args=[d.arg(name='value', type=d.T.string)]),
          withValue(value): { value: value },
        },
        '#withNodeSelector':: d.fn(help='"NodeSelector is the simplest recommended form of node selection constraint\\nand specifies a map of key-value pairs. For the pod to be eligible\\nto run on a node, the node must have each of the indicated key-value pairs\\nas labels (it can have additional labels as well).\\nIf unset, the pod(s) will be scheduled to any available node."', args=[d.arg(name='nodeSelector', type=d.T.object)]),
        withNodeSelector(nodeSelector): { spec+: { envoy+: { nodePlacement+: { nodeSelector: nodeSelector } } } },
        '#withNodeSelectorMixin':: d.fn(help='"NodeSelector is the simplest recommended form of node selection constraint\\nand specifies a map of key-value pairs. For the pod to be eligible\\nto run on a node, the node must have each of the indicated key-value pairs\\nas labels (it can have additional labels as well).\\nIf unset, the pod(s) will be scheduled to any available node."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='nodeSelector', type=d.T.object)]),
        withNodeSelectorMixin(nodeSelector): { spec+: { envoy+: { nodePlacement+: { nodeSelector+: nodeSelector } } } },
        '#withTolerations':: d.fn(help='"Tolerations work with taints to ensure that pods are not scheduled\\nonto inappropriate nodes. One or more taints are applied to a node; this\\nmarks that the node should not accept any pods that do not tolerate the\\ntaints.\\nThe default is an empty list.\\nSee https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\\nfor additional details."', args=[d.arg(name='tolerations', type=d.T.array)]),
        withTolerations(tolerations): { spec+: { envoy+: { nodePlacement+: { tolerations: if std.isArray(v=tolerations) then tolerations else [tolerations] } } } },
        '#withTolerationsMixin':: d.fn(help='"Tolerations work with taints to ensure that pods are not scheduled\\nonto inappropriate nodes. One or more taints are applied to a node; this\\nmarks that the node should not accept any pods that do not tolerate the\\ntaints.\\nThe default is an empty list.\\nSee https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\\nfor additional details."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='tolerations', type=d.T.array)]),
        withTolerationsMixin(tolerations): { spec+: { envoy+: { nodePlacement+: { tolerations+: if std.isArray(v=tolerations) then tolerations else [tolerations] } } } },
      },
      '#resources':: d.obj(help='"Compute Resources required by envoy container.\\nCannot be updated.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"'),
      resources: {
        '#claims':: d.obj(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\nThis is an alpha field and requires enabling the\\nDynamicResourceAllocation feature gate.\\nThis field is immutable. It can only be set for containers."'),
        claims: {
          '#withName':: d.fn(help='"Name must match the name of one entry in pod.spec.resourceClaims of\\nthe Pod where this field is used. It makes that resource available\\ninside a container."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { name: name },
        },
        '#withClaims':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\nThis is an alpha field and requires enabling the\\nDynamicResourceAllocation feature gate.\\nThis field is immutable. It can only be set for containers."', args=[d.arg(name='claims', type=d.T.array)]),
        withClaims(claims): { spec+: { envoy+: { resources+: { claims: if std.isArray(v=claims) then claims else [claims] } } } },
        '#withClaimsMixin':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\nThis is an alpha field and requires enabling the\\nDynamicResourceAllocation feature gate.\\nThis field is immutable. It can only be set for containers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='claims', type=d.T.array)]),
        withClaimsMixin(claims): { spec+: { envoy+: { resources+: { claims+: if std.isArray(v=claims) then claims else [claims] } } } },
        '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
        withLimits(limits): { spec+: { envoy+: { resources+: { limits: limits } } } },
        '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
        withLimitsMixin(limits): { spec+: { envoy+: { resources+: { limits+: limits } } } },
        '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
        withRequests(requests): { spec+: { envoy+: { resources+: { requests: requests } } } },
        '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
        withRequestsMixin(requests): { spec+: { envoy+: { resources+: { requests+: requests } } } },
      },
      '#withBaseID':: d.fn(help='"The base ID to use when allocating shared memory regions.\\nif Envoy needs to be run multiple times on the same machine, each running Envoy will need a unique base ID\\nso that the shared memory regions do not conflict.\\ndefaults to 0."', args=[d.arg(name='baseID', type=d.T.integer)]),
      withBaseID(baseID): { spec+: { envoy+: { baseID: baseID } } },
      '#withExtraVolumeMounts':: d.fn(help='"ExtraVolumeMounts holds the extra volume mounts to add (normally used with extraVolumes)."', args=[d.arg(name='extraVolumeMounts', type=d.T.array)]),
      withExtraVolumeMounts(extraVolumeMounts): { spec+: { envoy+: { extraVolumeMounts: if std.isArray(v=extraVolumeMounts) then extraVolumeMounts else [extraVolumeMounts] } } },
      '#withExtraVolumeMountsMixin':: d.fn(help='"ExtraVolumeMounts holds the extra volume mounts to add (normally used with extraVolumes)."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='extraVolumeMounts', type=d.T.array)]),
      withExtraVolumeMountsMixin(extraVolumeMounts): { spec+: { envoy+: { extraVolumeMounts+: if std.isArray(v=extraVolumeMounts) then extraVolumeMounts else [extraVolumeMounts] } } },
      '#withExtraVolumes':: d.fn(help='"ExtraVolumes holds the extra volumes to add."', args=[d.arg(name='extraVolumes', type=d.T.array)]),
      withExtraVolumes(extraVolumes): { spec+: { envoy+: { extraVolumes: if std.isArray(v=extraVolumes) then extraVolumes else [extraVolumes] } } },
      '#withExtraVolumesMixin':: d.fn(help='"ExtraVolumes holds the extra volumes to add."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='extraVolumes', type=d.T.array)]),
      withExtraVolumesMixin(extraVolumes): { spec+: { envoy+: { extraVolumes+: if std.isArray(v=extraVolumes) then extraVolumes else [extraVolumes] } } },
      '#withLogLevel':: d.fn(help='"LogLevel sets the log level for Envoy.\\nAllowed values are \\"trace\\", \\"debug\\", \\"info\\", \\"warn\\", \\"error\\", \\"critical\\", \\"off\\"."', args=[d.arg(name='logLevel', type=d.T.string)]),
      withLogLevel(logLevel): { spec+: { envoy+: { logLevel: logLevel } } },
      '#withOverloadMaxHeapSize':: d.fn(help='"OverloadMaxHeapSize defines the maximum heap memory of the envoy controlled by the overload manager.\\nWhen the value is greater than 0, the overload manager is enabled,\\nand when envoy reaches 95% of the maximum heap size, it performs a shrink heap operation,\\nWhen it reaches 98% of the maximum heap size, Envoy Will stop accepting requests.\\nMore info: https://projectcontour.io/docs/main/config/overload-manager/"', args=[d.arg(name='overloadMaxHeapSize', type=d.T.integer)]),
      withOverloadMaxHeapSize(overloadMaxHeapSize): { spec+: { envoy+: { overloadMaxHeapSize: overloadMaxHeapSize } } },
      '#withPodAnnotations':: d.fn(help='"PodAnnotations defines annotations to add to the Envoy pods.\\nthe annotations for Prometheus will be appended or overwritten with predefined value."', args=[d.arg(name='podAnnotations', type=d.T.object)]),
      withPodAnnotations(podAnnotations): { spec+: { envoy+: { podAnnotations: podAnnotations } } },
      '#withPodAnnotationsMixin':: d.fn(help='"PodAnnotations defines annotations to add to the Envoy pods.\\nthe annotations for Prometheus will be appended or overwritten with predefined value."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='podAnnotations', type=d.T.object)]),
      withPodAnnotationsMixin(podAnnotations): { spec+: { envoy+: { podAnnotations+: podAnnotations } } },
      '#withReplicas':: d.fn(help='"Deprecated: Use `DeploymentSettings.Replicas` instead.\\nReplicas is the desired number of Envoy replicas. If WorkloadType\\nis not \\"Deployment\\", this field is ignored. Otherwise, if unset,\\ndefaults to 2.\\nif both `DeploymentSettings.Replicas` and this one is set, use `DeploymentSettings.Replicas`."', args=[d.arg(name='replicas', type=d.T.integer)]),
      withReplicas(replicas): { spec+: { envoy+: { replicas: replicas } } },
      '#withWorkloadType':: d.fn(help='"WorkloadType is the type of workload to install Envoy\\nas. Choices are DaemonSet and Deployment. If unset, defaults\\nto DaemonSet."', args=[d.arg(name='workloadType', type=d.T.string)]),
      withWorkloadType(workloadType): { spec+: { envoy+: { workloadType: workloadType } } },
    },
    '#runtimeSettings':: d.obj(help="\"RuntimeSettings is a ContourConfiguration spec to be used when\\nprovisioning a Contour instance that will influence aspects of\\nthe Contour instance's runtime behavior.\""),
    runtimeSettings: {
      '#debug':: d.obj(help='"Debug contains parameters to enable debug logging\\nand debug interfaces inside Contour."'),
      debug: {
        '#withAddress':: d.fn(help="\"Defines the Contour debug address interface.\\nContour's default is \\\"127.0.0.1\\\".\"", args=[d.arg(name='address', type=d.T.string)]),
        withAddress(address): { spec+: { runtimeSettings+: { debug+: { address: address } } } },
        '#withPort':: d.fn(help="\"Defines the Contour debug address port.\\nContour's default is 6060.\"", args=[d.arg(name='port', type=d.T.integer)]),
        withPort(port): { spec+: { runtimeSettings+: { debug+: { port: port } } } },
      },
      '#envoy':: d.obj(help='"Envoy contains parameters for Envoy as well\\nas how to optionally configure a managed Envoy fleet."'),
      envoy: {
        '#clientCertificate':: d.obj(help='"ClientCertificate defines the namespace/name of the Kubernetes\\nsecret containing the client certificate and private key\\nto be used when establishing TLS connection to upstream\\ncluster."'),
        clientCertificate: {
          '#withName':: d.fn(help='', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { spec+: { runtimeSettings+: { envoy+: { clientCertificate+: { name: name } } } } },
          '#withNamespace':: d.fn(help='', args=[d.arg(name='namespace', type=d.T.string)]),
          withNamespace(namespace): { spec+: { runtimeSettings+: { envoy+: { clientCertificate+: { namespace: namespace } } } } },
        },
        '#cluster':: d.obj(help='"Cluster holds various configurable Envoy cluster values that can\\nbe set in the config file."'),
        cluster: {
          '#circuitBreakers':: d.obj(help='"GlobalCircuitBreakerDefaults specifies default circuit breaker budget across all services.\\nIf defined, this will be used as the default for all services."'),
          circuitBreakers: {
            '#withMaxConnections':: d.fn(help='"The maximum number of connections that a single Envoy instance allows to the Kubernetes Service; defaults to 1024."', args=[d.arg(name='maxConnections', type=d.T.integer)]),
            withMaxConnections(maxConnections): { spec+: { runtimeSettings+: { envoy+: { cluster+: { circuitBreakers+: { maxConnections: maxConnections } } } } } },
            '#withMaxPendingRequests':: d.fn(help='"The maximum number of pending requests that a single Envoy instance allows to the Kubernetes Service; defaults to 1024."', args=[d.arg(name='maxPendingRequests', type=d.T.integer)]),
            withMaxPendingRequests(maxPendingRequests): { spec+: { runtimeSettings+: { envoy+: { cluster+: { circuitBreakers+: { maxPendingRequests: maxPendingRequests } } } } } },
            '#withMaxRequests':: d.fn(help='"The maximum parallel requests a single Envoy instance allows to the Kubernetes Service; defaults to 1024"', args=[d.arg(name='maxRequests', type=d.T.integer)]),
            withMaxRequests(maxRequests): { spec+: { runtimeSettings+: { envoy+: { cluster+: { circuitBreakers+: { maxRequests: maxRequests } } } } } },
            '#withMaxRetries':: d.fn(help='"The maximum number of parallel retries a single Envoy instance allows to the Kubernetes Service; defaults to 3."', args=[d.arg(name='maxRetries', type=d.T.integer)]),
            withMaxRetries(maxRetries): { spec+: { runtimeSettings+: { envoy+: { cluster+: { circuitBreakers+: { maxRetries: maxRetries } } } } } },
          },
          '#upstreamTLS':: d.obj(help='"UpstreamTLS contains the TLS policy parameters for upstream connections"'),
          upstreamTLS: {
            '#withCipherSuites':: d.fn(help="\"CipherSuites defines the TLS ciphers to be supported by Envoy TLS\\nlisteners when negotiating TLS 1.2. Ciphers are validated against the\\nset that Envoy supports by default. This parameter should only be used\\nby advanced users. Note that these will be ignored when TLS 1.3 is in\\nuse.\\nThis field is optional; when it is undefined, a Contour-managed ciphersuite list\\nwill be used, which may be updated to keep it secure.\\nContour's default list is:\\n  - \\\"[ECDHE-ECDSA-AES128-GCM-SHA256|ECDHE-ECDSA-CHACHA20-POLY1305]\\\"\\n  - \\\"[ECDHE-RSA-AES128-GCM-SHA256|ECDHE-RSA-CHACHA20-POLY1305]\\\"\\n  - \\\"ECDHE-ECDSA-AES256-GCM-SHA384\\\"\\n  - \\\"ECDHE-RSA-AES256-GCM-SHA384\\\"\\nCiphers provided are validated against the following list:\\n  - \\\"[ECDHE-ECDSA-AES128-GCM-SHA256|ECDHE-ECDSA-CHACHA20-POLY1305]\\\"\\n  - \\\"[ECDHE-RSA-AES128-GCM-SHA256|ECDHE-RSA-CHACHA20-POLY1305]\\\"\\n  - \\\"ECDHE-ECDSA-AES128-GCM-SHA256\\\"\\n  - \\\"ECDHE-RSA-AES128-GCM-SHA256\\\"\\n  - \\\"ECDHE-ECDSA-AES128-SHA\\\"\\n  - \\\"ECDHE-RSA-AES128-SHA\\\"\\n  - \\\"AES128-GCM-SHA256\\\"\\n  - \\\"AES128-SHA\\\"\\n  - \\\"ECDHE-ECDSA-AES256-GCM-SHA384\\\"\\n  - \\\"ECDHE-RSA-AES256-GCM-SHA384\\\"\\n  - \\\"ECDHE-ECDSA-AES256-SHA\\\"\\n  - \\\"ECDHE-RSA-AES256-SHA\\\"\\n  - \\\"AES256-GCM-SHA384\\\"\\n  - \\\"AES256-SHA\\\"\\nContour recommends leaving this undefined unless you are sure you must.\\nSee: https://www.envoyproxy.io/docs/envoy/latest/api-v3/extensions/transport_sockets/tls/v3/common.proto#extensions-transport-sockets-tls-v3-tlsparameters\\nNote: This list is a superset of what is valid for stock Envoy builds and those using BoringSSL FIPS.\"", args=[d.arg(name='cipherSuites', type=d.T.array)]),
            withCipherSuites(cipherSuites): { spec+: { runtimeSettings+: { envoy+: { cluster+: { upstreamTLS+: { cipherSuites: if std.isArray(v=cipherSuites) then cipherSuites else [cipherSuites] } } } } } },
            '#withCipherSuitesMixin':: d.fn(help="\"CipherSuites defines the TLS ciphers to be supported by Envoy TLS\\nlisteners when negotiating TLS 1.2. Ciphers are validated against the\\nset that Envoy supports by default. This parameter should only be used\\nby advanced users. Note that these will be ignored when TLS 1.3 is in\\nuse.\\nThis field is optional; when it is undefined, a Contour-managed ciphersuite list\\nwill be used, which may be updated to keep it secure.\\nContour's default list is:\\n  - \\\"[ECDHE-ECDSA-AES128-GCM-SHA256|ECDHE-ECDSA-CHACHA20-POLY1305]\\\"\\n  - \\\"[ECDHE-RSA-AES128-GCM-SHA256|ECDHE-RSA-CHACHA20-POLY1305]\\\"\\n  - \\\"ECDHE-ECDSA-AES256-GCM-SHA384\\\"\\n  - \\\"ECDHE-RSA-AES256-GCM-SHA384\\\"\\nCiphers provided are validated against the following list:\\n  - \\\"[ECDHE-ECDSA-AES128-GCM-SHA256|ECDHE-ECDSA-CHACHA20-POLY1305]\\\"\\n  - \\\"[ECDHE-RSA-AES128-GCM-SHA256|ECDHE-RSA-CHACHA20-POLY1305]\\\"\\n  - \\\"ECDHE-ECDSA-AES128-GCM-SHA256\\\"\\n  - \\\"ECDHE-RSA-AES128-GCM-SHA256\\\"\\n  - \\\"ECDHE-ECDSA-AES128-SHA\\\"\\n  - \\\"ECDHE-RSA-AES128-SHA\\\"\\n  - \\\"AES128-GCM-SHA256\\\"\\n  - \\\"AES128-SHA\\\"\\n  - \\\"ECDHE-ECDSA-AES256-GCM-SHA384\\\"\\n  - \\\"ECDHE-RSA-AES256-GCM-SHA384\\\"\\n  - \\\"ECDHE-ECDSA-AES256-SHA\\\"\\n  - \\\"ECDHE-RSA-AES256-SHA\\\"\\n  - \\\"AES256-GCM-SHA384\\\"\\n  - \\\"AES256-SHA\\\"\\nContour recommends leaving this undefined unless you are sure you must.\\nSee: https://www.envoyproxy.io/docs/envoy/latest/api-v3/extensions/transport_sockets/tls/v3/common.proto#extensions-transport-sockets-tls-v3-tlsparameters\\nNote: This list is a superset of what is valid for stock Envoy builds and those using BoringSSL FIPS.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='cipherSuites', type=d.T.array)]),
            withCipherSuitesMixin(cipherSuites): { spec+: { runtimeSettings+: { envoy+: { cluster+: { upstreamTLS+: { cipherSuites+: if std.isArray(v=cipherSuites) then cipherSuites else [cipherSuites] } } } } } },
            '#withMaximumProtocolVersion':: d.fn(help='"MaximumProtocolVersion is the maximum TLS version this vhost should\\nnegotiate.\\nValues: `1.2`, `1.3`(default).\\nOther values will produce an error."', args=[d.arg(name='maximumProtocolVersion', type=d.T.string)]),
            withMaximumProtocolVersion(maximumProtocolVersion): { spec+: { runtimeSettings+: { envoy+: { cluster+: { upstreamTLS+: { maximumProtocolVersion: maximumProtocolVersion } } } } } },
            '#withMinimumProtocolVersion':: d.fn(help='"MinimumProtocolVersion is the minimum TLS version this vhost should\\nnegotiate.\\nValues: `1.2` (default), `1.3`.\\nOther values will produce an error."', args=[d.arg(name='minimumProtocolVersion', type=d.T.string)]),
            withMinimumProtocolVersion(minimumProtocolVersion): { spec+: { runtimeSettings+: { envoy+: { cluster+: { upstreamTLS+: { minimumProtocolVersion: minimumProtocolVersion } } } } } },
          },
          '#withDnsLookupFamily':: d.fn(help='"DNSLookupFamily defines how external names are looked up\\nWhen configured as V4, the DNS resolver will only perform a lookup\\nfor addresses in the IPv4 family. If V6 is configured, the DNS resolver\\nwill only perform a lookup for addresses in the IPv6 family.\\nIf AUTO is configured, the DNS resolver will first perform a lookup\\nfor addresses in the IPv6 family and fallback to a lookup for addresses\\nin the IPv4 family. If ALL is specified, the DNS resolver will perform a lookup for\\nboth IPv4 and IPv6 families, and return all resolved addresses.\\nWhen this is used, Happy Eyeballs will be enabled for upstream connections.\\nRefer to Happy Eyeballs Support for more information.\\nNote: This only applies to externalName clusters.\\nSee https://www.envoyproxy.io/docs/envoy/latest/api-v3/config/cluster/v3/cluster.proto.html#envoy-v3-api-enum-config-cluster-v3-cluster-dnslookupfamily\\nfor more information.\\nValues: `auto` (default), `v4`, `v6`, `all`.\\nOther values will produce an error."', args=[d.arg(name='dnsLookupFamily', type=d.T.string)]),
          withDnsLookupFamily(dnsLookupFamily): { spec+: { runtimeSettings+: { envoy+: { cluster+: { dnsLookupFamily: dnsLookupFamily } } } } },
          '#withMaxRequestsPerConnection':: d.fn(help='"Defines the maximum requests for upstream connections. If not specified, there is no limit.\\nsee https://www.envoyproxy.io/docs/envoy/latest/api-v3/config/core/v3/protocol.proto#envoy-v3-api-msg-config-core-v3-httpprotocoloptions\\nfor more information."', args=[d.arg(name='maxRequestsPerConnection', type=d.T.integer)]),
          withMaxRequestsPerConnection(maxRequestsPerConnection): { spec+: { runtimeSettings+: { envoy+: { cluster+: { maxRequestsPerConnection: maxRequestsPerConnection } } } } },
          '#withPer-Connection-Buffer-Limit-Bytes':: d.fn(help='"Defines the soft limit on size of the clusters new connection read and write buffers in bytes.\\nIf unspecified, an implementation defined default is applied (1MiB).\\nsee https://www.envoyproxy.io/docs/envoy/latest/api-v3/config/cluster/v3/cluster.proto#envoy-v3-api-field-config-cluster-v3-cluster-per-connection-buffer-limit-bytes\\nfor more information."', args=[d.arg(name='per_connection_buffer_limit_bytes', type=d.T.integer)]),
          'withPer-Connection-Buffer-Limit-Bytes'(per_connection_buffer_limit_bytes): { spec+: { runtimeSettings+: { envoy+: { cluster+: { 'per-connection-buffer-limit-bytes': per_connection_buffer_limit_bytes } } } } },
        },
        '#health':: d.obj(help="\"Health defines the endpoint Envoy uses to serve health checks.\\nContour's default is { address: \\\"0.0.0.0\\\", port: 8002 }.\""),
        health: {
          '#withAddress':: d.fn(help='"Defines the health address interface."', args=[d.arg(name='address', type=d.T.string)]),
          withAddress(address): { spec+: { runtimeSettings+: { envoy+: { health+: { address: address } } } } },
          '#withPort':: d.fn(help='"Defines the health port."', args=[d.arg(name='port', type=d.T.integer)]),
          withPort(port): { spec+: { runtimeSettings+: { envoy+: { health+: { port: port } } } } },
        },
        '#http':: d.obj(help="\"Defines the HTTP Listener for Envoy.\\nContour's default is { address: \\\"0.0.0.0\\\", port: 8080, accessLog: \\\"/dev/stdout\\\" }.\""),
        http: {
          '#withAccessLog':: d.fn(help='"AccessLog defines where Envoy logs are outputted for this listener."', args=[d.arg(name='accessLog', type=d.T.string)]),
          withAccessLog(accessLog): { spec+: { runtimeSettings+: { envoy+: { http+: { accessLog: accessLog } } } } },
          '#withAddress':: d.fn(help='"Defines an Envoy Listener Address."', args=[d.arg(name='address', type=d.T.string)]),
          withAddress(address): { spec+: { runtimeSettings+: { envoy+: { http+: { address: address } } } } },
          '#withPort':: d.fn(help='"Defines an Envoy listener Port."', args=[d.arg(name='port', type=d.T.integer)]),
          withPort(port): { spec+: { runtimeSettings+: { envoy+: { http+: { port: port } } } } },
        },
        '#https':: d.obj(help="\"Defines the HTTPS Listener for Envoy.\\nContour's default is { address: \\\"0.0.0.0\\\", port: 8443, accessLog: \\\"/dev/stdout\\\" }.\""),
        https: {
          '#withAccessLog':: d.fn(help='"AccessLog defines where Envoy logs are outputted for this listener."', args=[d.arg(name='accessLog', type=d.T.string)]),
          withAccessLog(accessLog): { spec+: { runtimeSettings+: { envoy+: { https+: { accessLog: accessLog } } } } },
          '#withAddress':: d.fn(help='"Defines an Envoy Listener Address."', args=[d.arg(name='address', type=d.T.string)]),
          withAddress(address): { spec+: { runtimeSettings+: { envoy+: { https+: { address: address } } } } },
          '#withPort':: d.fn(help='"Defines an Envoy listener Port."', args=[d.arg(name='port', type=d.T.integer)]),
          withPort(port): { spec+: { runtimeSettings+: { envoy+: { https+: { port: port } } } } },
        },
        '#listener':: d.obj(help='"Listener hold various configurable Envoy listener values."'),
        listener: {
          '#socketOptions':: d.obj(help='"SocketOptions defines configurable socket options for the listeners.\\nSingle set of options are applied to all listeners."'),
          socketOptions: {
            '#withTos':: d.fn(help='"Defines the value for IPv4 TOS field (including 6 bit DSCP field) for IP packets originating from Envoy listeners.\\nSingle value is applied to all listeners.\\nIf listeners are bound to IPv6-only addresses, setting this option will cause an error."', args=[d.arg(name='tos', type=d.T.integer)]),
            withTos(tos): { spec+: { runtimeSettings+: { envoy+: { listener+: { socketOptions+: { tos: tos } } } } } },
            '#withTrafficClass':: d.fn(help='"Defines the value for IPv6 Traffic Class field (including 6 bit DSCP field) for IP packets originating from the Envoy listeners.\\nSingle value is applied to all listeners.\\nIf listeners are bound to IPv4-only addresses, setting this option will cause an error."', args=[d.arg(name='trafficClass', type=d.T.integer)]),
            withTrafficClass(trafficClass): { spec+: { runtimeSettings+: { envoy+: { listener+: { socketOptions+: { trafficClass: trafficClass } } } } } },
          },
          '#tls':: d.obj(help='"TLS holds various configurable Envoy TLS listener values."'),
          tls: {
            '#withCipherSuites':: d.fn(help="\"CipherSuites defines the TLS ciphers to be supported by Envoy TLS\\nlisteners when negotiating TLS 1.2. Ciphers are validated against the\\nset that Envoy supports by default. This parameter should only be used\\nby advanced users. Note that these will be ignored when TLS 1.3 is in\\nuse.\\nThis field is optional; when it is undefined, a Contour-managed ciphersuite list\\nwill be used, which may be updated to keep it secure.\\nContour's default list is:\\n  - \\\"[ECDHE-ECDSA-AES128-GCM-SHA256|ECDHE-ECDSA-CHACHA20-POLY1305]\\\"\\n  - \\\"[ECDHE-RSA-AES128-GCM-SHA256|ECDHE-RSA-CHACHA20-POLY1305]\\\"\\n  - \\\"ECDHE-ECDSA-AES256-GCM-SHA384\\\"\\n  - \\\"ECDHE-RSA-AES256-GCM-SHA384\\\"\\nCiphers provided are validated against the following list:\\n  - \\\"[ECDHE-ECDSA-AES128-GCM-SHA256|ECDHE-ECDSA-CHACHA20-POLY1305]\\\"\\n  - \\\"[ECDHE-RSA-AES128-GCM-SHA256|ECDHE-RSA-CHACHA20-POLY1305]\\\"\\n  - \\\"ECDHE-ECDSA-AES128-GCM-SHA256\\\"\\n  - \\\"ECDHE-RSA-AES128-GCM-SHA256\\\"\\n  - \\\"ECDHE-ECDSA-AES128-SHA\\\"\\n  - \\\"ECDHE-RSA-AES128-SHA\\\"\\n  - \\\"AES128-GCM-SHA256\\\"\\n  - \\\"AES128-SHA\\\"\\n  - \\\"ECDHE-ECDSA-AES256-GCM-SHA384\\\"\\n  - \\\"ECDHE-RSA-AES256-GCM-SHA384\\\"\\n  - \\\"ECDHE-ECDSA-AES256-SHA\\\"\\n  - \\\"ECDHE-RSA-AES256-SHA\\\"\\n  - \\\"AES256-GCM-SHA384\\\"\\n  - \\\"AES256-SHA\\\"\\nContour recommends leaving this undefined unless you are sure you must.\\nSee: https://www.envoyproxy.io/docs/envoy/latest/api-v3/extensions/transport_sockets/tls/v3/common.proto#extensions-transport-sockets-tls-v3-tlsparameters\\nNote: This list is a superset of what is valid for stock Envoy builds and those using BoringSSL FIPS.\"", args=[d.arg(name='cipherSuites', type=d.T.array)]),
            withCipherSuites(cipherSuites): { spec+: { runtimeSettings+: { envoy+: { listener+: { tls+: { cipherSuites: if std.isArray(v=cipherSuites) then cipherSuites else [cipherSuites] } } } } } },
            '#withCipherSuitesMixin':: d.fn(help="\"CipherSuites defines the TLS ciphers to be supported by Envoy TLS\\nlisteners when negotiating TLS 1.2. Ciphers are validated against the\\nset that Envoy supports by default. This parameter should only be used\\nby advanced users. Note that these will be ignored when TLS 1.3 is in\\nuse.\\nThis field is optional; when it is undefined, a Contour-managed ciphersuite list\\nwill be used, which may be updated to keep it secure.\\nContour's default list is:\\n  - \\\"[ECDHE-ECDSA-AES128-GCM-SHA256|ECDHE-ECDSA-CHACHA20-POLY1305]\\\"\\n  - \\\"[ECDHE-RSA-AES128-GCM-SHA256|ECDHE-RSA-CHACHA20-POLY1305]\\\"\\n  - \\\"ECDHE-ECDSA-AES256-GCM-SHA384\\\"\\n  - \\\"ECDHE-RSA-AES256-GCM-SHA384\\\"\\nCiphers provided are validated against the following list:\\n  - \\\"[ECDHE-ECDSA-AES128-GCM-SHA256|ECDHE-ECDSA-CHACHA20-POLY1305]\\\"\\n  - \\\"[ECDHE-RSA-AES128-GCM-SHA256|ECDHE-RSA-CHACHA20-POLY1305]\\\"\\n  - \\\"ECDHE-ECDSA-AES128-GCM-SHA256\\\"\\n  - \\\"ECDHE-RSA-AES128-GCM-SHA256\\\"\\n  - \\\"ECDHE-ECDSA-AES128-SHA\\\"\\n  - \\\"ECDHE-RSA-AES128-SHA\\\"\\n  - \\\"AES128-GCM-SHA256\\\"\\n  - \\\"AES128-SHA\\\"\\n  - \\\"ECDHE-ECDSA-AES256-GCM-SHA384\\\"\\n  - \\\"ECDHE-RSA-AES256-GCM-SHA384\\\"\\n  - \\\"ECDHE-ECDSA-AES256-SHA\\\"\\n  - \\\"ECDHE-RSA-AES256-SHA\\\"\\n  - \\\"AES256-GCM-SHA384\\\"\\n  - \\\"AES256-SHA\\\"\\nContour recommends leaving this undefined unless you are sure you must.\\nSee: https://www.envoyproxy.io/docs/envoy/latest/api-v3/extensions/transport_sockets/tls/v3/common.proto#extensions-transport-sockets-tls-v3-tlsparameters\\nNote: This list is a superset of what is valid for stock Envoy builds and those using BoringSSL FIPS.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='cipherSuites', type=d.T.array)]),
            withCipherSuitesMixin(cipherSuites): { spec+: { runtimeSettings+: { envoy+: { listener+: { tls+: { cipherSuites+: if std.isArray(v=cipherSuites) then cipherSuites else [cipherSuites] } } } } } },
            '#withMaximumProtocolVersion':: d.fn(help='"MaximumProtocolVersion is the maximum TLS version this vhost should\\nnegotiate.\\nValues: `1.2`, `1.3`(default).\\nOther values will produce an error."', args=[d.arg(name='maximumProtocolVersion', type=d.T.string)]),
            withMaximumProtocolVersion(maximumProtocolVersion): { spec+: { runtimeSettings+: { envoy+: { listener+: { tls+: { maximumProtocolVersion: maximumProtocolVersion } } } } } },
            '#withMinimumProtocolVersion':: d.fn(help='"MinimumProtocolVersion is the minimum TLS version this vhost should\\nnegotiate.\\nValues: `1.2` (default), `1.3`.\\nOther values will produce an error."', args=[d.arg(name='minimumProtocolVersion', type=d.T.string)]),
            withMinimumProtocolVersion(minimumProtocolVersion): { spec+: { runtimeSettings+: { envoy+: { listener+: { tls+: { minimumProtocolVersion: minimumProtocolVersion } } } } } },
          },
          '#withConnectionBalancer':: d.fn(help='"ConnectionBalancer. If the value is exact, the listener will use the exact connection balancer\\nSee https://www.envoyproxy.io/docs/envoy/latest/api-v2/api/v2/listener.proto#envoy-api-msg-listener-connectionbalanceconfig\\nfor more information.\\nValues: (empty string): use the default ConnectionBalancer, `exact`: use the Exact ConnectionBalancer.\\nOther values will produce an error."', args=[d.arg(name='connectionBalancer', type=d.T.string)]),
          withConnectionBalancer(connectionBalancer): { spec+: { runtimeSettings+: { envoy+: { listener+: { connectionBalancer: connectionBalancer } } } } },
          '#withDisableAllowChunkedLength':: d.fn(help="\"DisableAllowChunkedLength disables the RFC-compliant Envoy behavior to\\nstrip the \\\"Content-Length\\\" header if \\\"Transfer-Encoding: chunked\\\" is\\nalso set. This is an emergency off-switch to revert back to Envoy's\\ndefault behavior in case of failures. Please file an issue if failures\\nare encountered.\\nSee: https://github.com/projectcontour/contour/issues/3221\\nContour's default is false.\"", args=[d.arg(name='disableAllowChunkedLength', type=d.T.boolean)]),
          withDisableAllowChunkedLength(disableAllowChunkedLength): { spec+: { runtimeSettings+: { envoy+: { listener+: { disableAllowChunkedLength: disableAllowChunkedLength } } } } },
          '#withDisableMergeSlashes':: d.fn(help="\"DisableMergeSlashes disables Envoy's non-standard merge_slashes path transformation option\\nwhich strips duplicate slashes from request URL paths.\\nContour's default is false.\"", args=[d.arg(name='disableMergeSlashes', type=d.T.boolean)]),
          withDisableMergeSlashes(disableMergeSlashes): { spec+: { runtimeSettings+: { envoy+: { listener+: { disableMergeSlashes: disableMergeSlashes } } } } },
          '#withHttpMaxConcurrentStreams':: d.fn(help='"Defines the value for SETTINGS_MAX_CONCURRENT_STREAMS Envoy will advertise in the\\nSETTINGS frame in HTTP/2 connections and the limit for concurrent streams allowed\\nfor a peer on a single HTTP/2 connection. It is recommended to not set this lower\\nthan 100 but this field can be used to bound resource usage by HTTP/2 connections\\nand mitigate attacks like CVE-2023-44487. The default value when this is not set is\\nunlimited."', args=[d.arg(name='httpMaxConcurrentStreams', type=d.T.integer)]),
          withHttpMaxConcurrentStreams(httpMaxConcurrentStreams): { spec+: { runtimeSettings+: { envoy+: { listener+: { httpMaxConcurrentStreams: httpMaxConcurrentStreams } } } } },
          '#withMaxConnectionsPerListener':: d.fn(help='"Defines the limit on number of active connections to a listener. The limit is applied\\nper listener. The default value when this is not set is unlimited."', args=[d.arg(name='maxConnectionsPerListener', type=d.T.integer)]),
          withMaxConnectionsPerListener(maxConnectionsPerListener): { spec+: { runtimeSettings+: { envoy+: { listener+: { maxConnectionsPerListener: maxConnectionsPerListener } } } } },
          '#withMaxRequestsPerConnection':: d.fn(help='"Defines the maximum requests for downstream connections. If not specified, there is no limit.\\nsee https://www.envoyproxy.io/docs/envoy/latest/api-v3/config/core/v3/protocol.proto#envoy-v3-api-msg-config-core-v3-httpprotocoloptions\\nfor more information."', args=[d.arg(name='maxRequestsPerConnection', type=d.T.integer)]),
          withMaxRequestsPerConnection(maxRequestsPerConnection): { spec+: { runtimeSettings+: { envoy+: { listener+: { maxRequestsPerConnection: maxRequestsPerConnection } } } } },
          '#withMaxRequestsPerIOCycle':: d.fn(help='"Defines the limit on number of HTTP requests that Envoy will process from a single\\nconnection in a single I/O cycle. Requests over this limit are processed in subsequent\\nI/O cycles. Can be used as a mitigation for CVE-2023-44487 when abusive traffic is\\ndetected. Configures the http.max_requests_per_io_cycle Envoy runtime setting. The default\\nvalue when this is not set is no limit."', args=[d.arg(name='maxRequestsPerIOCycle', type=d.T.integer)]),
          withMaxRequestsPerIOCycle(maxRequestsPerIOCycle): { spec+: { runtimeSettings+: { envoy+: { listener+: { maxRequestsPerIOCycle: maxRequestsPerIOCycle } } } } },
          '#withPer-Connection-Buffer-Limit-Bytes':: d.fn(help='"Defines the soft limit on size of the listeners new connection read and write buffers in bytes.\\nIf unspecified, an implementation defined default is applied (1MiB).\\nsee https://www.envoyproxy.io/docs/envoy/latest/api-v3/config/listener/v3/listener.proto#envoy-v3-api-field-config-listener-v3-listener-per-connection-buffer-limit-bytes\\nfor more information."', args=[d.arg(name='per_connection_buffer_limit_bytes', type=d.T.integer)]),
          'withPer-Connection-Buffer-Limit-Bytes'(per_connection_buffer_limit_bytes): { spec+: { runtimeSettings+: { envoy+: { listener+: { 'per-connection-buffer-limit-bytes': per_connection_buffer_limit_bytes } } } } },
          '#withServerHeaderTransformation':: d.fn(help="\"Defines the action to be applied to the Server header on the response path.\\nWhen configured as overwrite, overwrites any Server header with \\\"envoy\\\".\\nWhen configured as append_if_absent, if a Server header is present, pass it through, otherwise set it to \\\"envoy\\\".\\nWhen configured as pass_through, pass through the value of the Server header, and do not append a header if none is present.\\nValues: `overwrite` (default), `append_if_absent`, `pass_through`\\nOther values will produce an error.\\nContour's default is overwrite.\"", args=[d.arg(name='serverHeaderTransformation', type=d.T.string)]),
          withServerHeaderTransformation(serverHeaderTransformation): { spec+: { runtimeSettings+: { envoy+: { listener+: { serverHeaderTransformation: serverHeaderTransformation } } } } },
          '#withUseProxyProtocol':: d.fn(help="\"Use PROXY protocol for all listeners.\\nContour's default is false.\"", args=[d.arg(name='useProxyProtocol', type=d.T.boolean)]),
          withUseProxyProtocol(useProxyProtocol): { spec+: { runtimeSettings+: { envoy+: { listener+: { useProxyProtocol: useProxyProtocol } } } } },
        },
        '#logging':: d.obj(help="\"Logging defines how Envoy's logs can be configured.\""),
        logging: {
          '#withAccessLogFormat':: d.fn(help='"AccessLogFormat sets the global access log format.\\nValues: `envoy` (default), `json`.\\nOther values will produce an error."', args=[d.arg(name='accessLogFormat', type=d.T.string)]),
          withAccessLogFormat(accessLogFormat): { spec+: { runtimeSettings+: { envoy+: { logging+: { accessLogFormat: accessLogFormat } } } } },
          '#withAccessLogFormatString':: d.fn(help="\"AccessLogFormatString sets the access log format when format is set to `envoy`.\\nWhen empty, Envoy's default format is used.\"", args=[d.arg(name='accessLogFormatString', type=d.T.string)]),
          withAccessLogFormatString(accessLogFormatString): { spec+: { runtimeSettings+: { envoy+: { logging+: { accessLogFormatString: accessLogFormatString } } } } },
          '#withAccessLogJSONFields':: d.fn(help='"AccessLogJSONFields sets the fields that JSON logging will\\noutput when AccessLogFormat is json."', args=[d.arg(name='accessLogJSONFields', type=d.T.array)]),
          withAccessLogJSONFields(accessLogJSONFields): { spec+: { runtimeSettings+: { envoy+: { logging+: { accessLogJSONFields: if std.isArray(v=accessLogJSONFields) then accessLogJSONFields else [accessLogJSONFields] } } } } },
          '#withAccessLogJSONFieldsMixin':: d.fn(help='"AccessLogJSONFields sets the fields that JSON logging will\\noutput when AccessLogFormat is json."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='accessLogJSONFields', type=d.T.array)]),
          withAccessLogJSONFieldsMixin(accessLogJSONFields): { spec+: { runtimeSettings+: { envoy+: { logging+: { accessLogJSONFields+: if std.isArray(v=accessLogJSONFields) then accessLogJSONFields else [accessLogJSONFields] } } } } },
          '#withAccessLogLevel':: d.fn(help='"AccessLogLevel sets the verbosity level of the access log.\\nValues: `info` (default, all requests are logged), `error` (all non-success requests, i.e. 300+ response code, are logged), `critical` (all 5xx requests are logged) and `disabled`.\\nOther values will produce an error."', args=[d.arg(name='accessLogLevel', type=d.T.string)]),
          withAccessLogLevel(accessLogLevel): { spec+: { runtimeSettings+: { envoy+: { logging+: { accessLogLevel: accessLogLevel } } } } },
        },
        '#metrics':: d.obj(help="\"Metrics defines the endpoint Envoy uses to serve metrics.\\nContour's default is { address: \\\"0.0.0.0\\\", port: 8002 }.\""),
        metrics: {
          '#tls':: d.obj(help='"TLS holds TLS file config details.\\nMetrics and health endpoints cannot have same port number when metrics is served over HTTPS."'),
          tls: {
            '#withCaFile':: d.fn(help='"CA filename."', args=[d.arg(name='caFile', type=d.T.string)]),
            withCaFile(caFile): { spec+: { runtimeSettings+: { envoy+: { metrics+: { tls+: { caFile: caFile } } } } } },
            '#withCertFile':: d.fn(help='"Client certificate filename."', args=[d.arg(name='certFile', type=d.T.string)]),
            withCertFile(certFile): { spec+: { runtimeSettings+: { envoy+: { metrics+: { tls+: { certFile: certFile } } } } } },
            '#withKeyFile':: d.fn(help='"Client key filename."', args=[d.arg(name='keyFile', type=d.T.string)]),
            withKeyFile(keyFile): { spec+: { runtimeSettings+: { envoy+: { metrics+: { tls+: { keyFile: keyFile } } } } } },
          },
          '#withAddress':: d.fn(help='"Defines the metrics address interface."', args=[d.arg(name='address', type=d.T.string)]),
          withAddress(address): { spec+: { runtimeSettings+: { envoy+: { metrics+: { address: address } } } } },
          '#withPort':: d.fn(help='"Defines the metrics port."', args=[d.arg(name='port', type=d.T.integer)]),
          withPort(port): { spec+: { runtimeSettings+: { envoy+: { metrics+: { port: port } } } } },
        },
        '#network':: d.obj(help='"Network holds various configurable Envoy network values."'),
        network: {
          '#withAdminPort':: d.fn(help="\"Configure the port used to access the Envoy Admin interface.\\nIf configured to port \\\"0\\\" then the admin interface is disabled.\\nContour's default is 9001.\"", args=[d.arg(name='adminPort', type=d.T.integer)]),
          withAdminPort(adminPort): { spec+: { runtimeSettings+: { envoy+: { network+: { adminPort: adminPort } } } } },
          '#withNumTrustedHops':: d.fn(help="\"XffNumTrustedHops defines the number of additional ingress proxy hops from the\\nright side of the x-forwarded-for HTTP header to trust when determining the origin\\nclients IP address.\\nSee https://www.envoyproxy.io/docs/envoy/v1.17.0/api-v3/extensions/filters/network/http_connection_manager/v3/http_connection_manager.proto?highlight=xff_num_trusted_hops\\nfor more information.\\nContour's default is 0.\"", args=[d.arg(name='numTrustedHops', type=d.T.integer)]),
          withNumTrustedHops(numTrustedHops): { spec+: { runtimeSettings+: { envoy+: { network+: { numTrustedHops: numTrustedHops } } } } },
        },
        '#service':: d.obj(help="\"Service holds Envoy service parameters for setting Ingress status.\\nContour's default is { namespace: \\\"projectcontour\\\", name: \\\"envoy\\\" }.\""),
        service: {
          '#withName':: d.fn(help='', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { spec+: { runtimeSettings+: { envoy+: { service+: { name: name } } } } },
          '#withNamespace':: d.fn(help='', args=[d.arg(name='namespace', type=d.T.string)]),
          withNamespace(namespace): { spec+: { runtimeSettings+: { envoy+: { service+: { namespace: namespace } } } } },
        },
        '#timeouts':: d.obj(help='"Timeouts holds various configurable timeouts that can\\nbe set in the config file."'),
        timeouts: {
          '#withConnectTimeout':: d.fn(help='"ConnectTimeout defines how long the proxy should wait when establishing connection to upstream service.\\nIf not set, a default value of 2 seconds will be used.\\nSee https://www.envoyproxy.io/docs/envoy/latest/api-v3/config/cluster/v3/cluster.proto#envoy-v3-api-field-config-cluster-v3-cluster-connect-timeout\\nfor more information."', args=[d.arg(name='connectTimeout', type=d.T.string)]),
          withConnectTimeout(connectTimeout): { spec+: { runtimeSettings+: { envoy+: { timeouts+: { connectTimeout: connectTimeout } } } } },
          '#withConnectionIdleTimeout':: d.fn(help='"ConnectionIdleTimeout defines how long the proxy should wait while there are\\nno active requests (for HTTP/1.1) or streams (for HTTP/2) before terminating\\nan HTTP connection. Set to \\"infinity\\" to disable the timeout entirely.\\nSee https://www.envoyproxy.io/docs/envoy/latest/api-v3/config/core/v3/protocol.proto#envoy-v3-api-field-config-core-v3-httpprotocoloptions-idle-timeout\\nfor more information."', args=[d.arg(name='connectionIdleTimeout', type=d.T.string)]),
          withConnectionIdleTimeout(connectionIdleTimeout): { spec+: { runtimeSettings+: { envoy+: { timeouts+: { connectionIdleTimeout: connectionIdleTimeout } } } } },
          '#withConnectionShutdownGracePeriod':: d.fn(help='"ConnectionShutdownGracePeriod defines how long the proxy will wait between sending an\\ninitial GOAWAY frame and a second, final GOAWAY frame when terminating an HTTP/2 connection.\\nDuring this grace period, the proxy will continue to respond to new streams. After the final\\nGOAWAY frame has been sent, the proxy will refuse new streams.\\nSee https://www.envoyproxy.io/docs/envoy/latest/api-v3/extensions/filters/network/http_connection_manager/v3/http_connection_manager.proto#envoy-v3-api-field-extensions-filters-network-http-connection-manager-v3-httpconnectionmanager-drain-timeout\\nfor more information."', args=[d.arg(name='connectionShutdownGracePeriod', type=d.T.string)]),
          withConnectionShutdownGracePeriod(connectionShutdownGracePeriod): { spec+: { runtimeSettings+: { envoy+: { timeouts+: { connectionShutdownGracePeriod: connectionShutdownGracePeriod } } } } },
          '#withDelayedCloseTimeout':: d.fn(help="\"DelayedCloseTimeout defines how long envoy will wait, once connection\\nclose processing has been initiated, for the downstream peer to close\\nthe connection before Envoy closes the socket associated with the connection.\\nSetting this timeout to 'infinity' will disable it, equivalent to setting it to '0'\\nin Envoy. Leaving it unset will result in the Envoy default value being used.\\nSee https://www.envoyproxy.io/docs/envoy/latest/api-v3/extensions/filters/network/http_connection_manager/v3/http_connection_manager.proto#envoy-v3-api-field-extensions-filters-network-http-connection-manager-v3-httpconnectionmanager-delayed-close-timeout\\nfor more information.\"", args=[d.arg(name='delayedCloseTimeout', type=d.T.string)]),
          withDelayedCloseTimeout(delayedCloseTimeout): { spec+: { runtimeSettings+: { envoy+: { timeouts+: { delayedCloseTimeout: delayedCloseTimeout } } } } },
          '#withMaxConnectionDuration':: d.fn(help='"MaxConnectionDuration defines the maximum period of time after an HTTP connection\\nhas been established from the client to the proxy before it is closed by the proxy,\\nregardless of whether there has been activity or not. Omit or set to \\"infinity\\" for\\nno max duration.\\nSee https://www.envoyproxy.io/docs/envoy/latest/api-v3/config/core/v3/protocol.proto#envoy-v3-api-field-config-core-v3-httpprotocoloptions-max-connection-duration\\nfor more information."', args=[d.arg(name='maxConnectionDuration', type=d.T.string)]),
          withMaxConnectionDuration(maxConnectionDuration): { spec+: { runtimeSettings+: { envoy+: { timeouts+: { maxConnectionDuration: maxConnectionDuration } } } } },
          '#withRequestTimeout':: d.fn(help='"RequestTimeout sets the client request timeout globally for Contour. Note that\\nthis is a timeout for the entire request, not an idle timeout. Omit or set to\\n\\"infinity\\" to disable the timeout entirely.\\nSee https://www.envoyproxy.io/docs/envoy/latest/api-v3/extensions/filters/network/http_connection_manager/v3/http_connection_manager.proto#envoy-v3-api-field-extensions-filters-network-http-connection-manager-v3-httpconnectionmanager-request-timeout\\nfor more information."', args=[d.arg(name='requestTimeout', type=d.T.string)]),
          withRequestTimeout(requestTimeout): { spec+: { runtimeSettings+: { envoy+: { timeouts+: { requestTimeout: requestTimeout } } } } },
          '#withStreamIdleTimeout':: d.fn(help='"StreamIdleTimeout defines how long the proxy should wait while there is no\\nrequest activity (for HTTP/1.1) or stream activity (for HTTP/2) before\\nterminating the HTTP request or stream. Set to \\"infinity\\" to disable the\\ntimeout entirely.\\nSee https://www.envoyproxy.io/docs/envoy/latest/api-v3/extensions/filters/network/http_connection_manager/v3/http_connection_manager.proto#envoy-v3-api-field-extensions-filters-network-http-connection-manager-v3-httpconnectionmanager-stream-idle-timeout\\nfor more information."', args=[d.arg(name='streamIdleTimeout', type=d.T.string)]),
          withStreamIdleTimeout(streamIdleTimeout): { spec+: { runtimeSettings+: { envoy+: { timeouts+: { streamIdleTimeout: streamIdleTimeout } } } } },
        },
        '#withDefaultHTTPVersions':: d.fn(help='"DefaultHTTPVersions defines the default set of HTTPS\\nversions the proxy should accept. HTTP versions are\\nstrings of the form \\"HTTP/xx\\". Supported versions are\\n\\"HTTP/1.1\\" and \\"HTTP/2\\".\\nValues: `HTTP/1.1`, `HTTP/2` (default: both).\\nOther values will produce an error."', args=[d.arg(name='defaultHTTPVersions', type=d.T.array)]),
        withDefaultHTTPVersions(defaultHTTPVersions): { spec+: { runtimeSettings+: { envoy+: { defaultHTTPVersions: if std.isArray(v=defaultHTTPVersions) then defaultHTTPVersions else [defaultHTTPVersions] } } } },
        '#withDefaultHTTPVersionsMixin':: d.fn(help='"DefaultHTTPVersions defines the default set of HTTPS\\nversions the proxy should accept. HTTP versions are\\nstrings of the form \\"HTTP/xx\\". Supported versions are\\n\\"HTTP/1.1\\" and \\"HTTP/2\\".\\nValues: `HTTP/1.1`, `HTTP/2` (default: both).\\nOther values will produce an error."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='defaultHTTPVersions', type=d.T.array)]),
        withDefaultHTTPVersionsMixin(defaultHTTPVersions): { spec+: { runtimeSettings+: { envoy+: { defaultHTTPVersions+: if std.isArray(v=defaultHTTPVersions) then defaultHTTPVersions else [defaultHTTPVersions] } } } },
      },
      '#gateway':: d.obj(help='"Gateway contains parameters for the gateway-api Gateway that Contour\\nis configured to serve traffic."'),
      gateway: {
        '#gatewayRef':: d.obj(help='"GatewayRef defines a specific Gateway that this Contour\\ninstance corresponds to. If set, Contour will reconcile\\nonly this gateway, and will not reconcile any gateway\\nclasses.\\nExactly one of ControllerName or GatewayRef must be set."'),
        gatewayRef: {
          '#withName':: d.fn(help='', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { spec+: { runtimeSettings+: { gateway+: { gatewayRef+: { name: name } } } } },
          '#withNamespace':: d.fn(help='', args=[d.arg(name='namespace', type=d.T.string)]),
          withNamespace(namespace): { spec+: { runtimeSettings+: { gateway+: { gatewayRef+: { namespace: namespace } } } } },
        },
        '#withControllerName':: d.fn(help='"ControllerName is used to determine whether Contour should reconcile a\\nGatewayClass. The string takes the form of \\"projectcontour.io/<namespace>/contour\\".\\nIf unset, the gatewayclass controller will not be started.\\nExactly one of ControllerName or GatewayRef must be set.\\nDeprecated: users should use GatewayRef, or the Gateway provisioner,\\nin place of this field. This field will be removed in a future release."', args=[d.arg(name='controllerName', type=d.T.string)]),
        withControllerName(controllerName): { spec+: { runtimeSettings+: { gateway+: { controllerName: controllerName } } } },
      },
      '#globalExtAuth':: d.obj(help='"GlobalExternalAuthorization allows envoys external authorization filter\\nto be enabled for all virtual hosts."'),
      globalExtAuth: {
        '#authPolicy':: d.obj(help='"AuthPolicy sets a default authorization policy for client requests.\\nThis policy will be used unless overridden by individual routes."'),
        authPolicy: {
          '#withContext':: d.fn(help='"Context is a set of key/value pairs that are sent to the\\nauthentication server in the check request. If a context\\nis provided at an enclosing scope, the entries are merged\\nsuch that the inner scope overrides matching keys from the\\nouter scope."', args=[d.arg(name='context', type=d.T.object)]),
          withContext(context): { spec+: { runtimeSettings+: { globalExtAuth+: { authPolicy+: { context: context } } } } },
          '#withContextMixin':: d.fn(help='"Context is a set of key/value pairs that are sent to the\\nauthentication server in the check request. If a context\\nis provided at an enclosing scope, the entries are merged\\nsuch that the inner scope overrides matching keys from the\\nouter scope."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='context', type=d.T.object)]),
          withContextMixin(context): { spec+: { runtimeSettings+: { globalExtAuth+: { authPolicy+: { context+: context } } } } },
          '#withDisabled':: d.fn(help='"When true, this field disables client request authentication\\nfor the scope of the policy."', args=[d.arg(name='disabled', type=d.T.boolean)]),
          withDisabled(disabled): { spec+: { runtimeSettings+: { globalExtAuth+: { authPolicy+: { disabled: disabled } } } } },
        },
        '#extensionRef':: d.obj(help='"ExtensionServiceRef specifies the extension resource that will authorize client requests."'),
        extensionRef: {
          '#withApiVersion':: d.fn(help='"API version of the referent.\\nIf this field is not specified, the default \\"projectcontour.io/v1alpha1\\" will be used"', args=[d.arg(name='apiVersion', type=d.T.string)]),
          withApiVersion(apiVersion): { spec+: { runtimeSettings+: { globalExtAuth+: { extensionRef+: { apiVersion: apiVersion } } } } },
          '#withName':: d.fn(help='"Name of the referent.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { spec+: { runtimeSettings+: { globalExtAuth+: { extensionRef+: { name: name } } } } },
          '#withNamespace':: d.fn(help='"Namespace of the referent.\\nIf this field is not specifies, the namespace of the resource that targets the referent will be used.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/"', args=[d.arg(name='namespace', type=d.T.string)]),
          withNamespace(namespace): { spec+: { runtimeSettings+: { globalExtAuth+: { extensionRef+: { namespace: namespace } } } } },
        },
        '#withFailOpen':: d.fn(help='"If FailOpen is true, the client request is forwarded to the upstream service\\neven if the authorization server fails to respond. This field should not be\\nset in most cases. It is intended for use only while migrating applications\\nfrom internal authorization to Contour external authorization."', args=[d.arg(name='failOpen', type=d.T.boolean)]),
        withFailOpen(failOpen): { spec+: { runtimeSettings+: { globalExtAuth+: { failOpen: failOpen } } } },
        '#withRequestBody':: d.obj(help="\"WithRequestBody specifies configuration for sending the client request's body to authorization server.\""),
        withRequestBody: {
          '#withAllowPartialMessage':: d.fn(help='"If AllowPartialMessage is true, then Envoy will buffer the body until MaxRequestBytes are reached."', args=[d.arg(name='allowPartialMessage', type=d.T.boolean)]),
          withAllowPartialMessage(allowPartialMessage): { spec+: { runtimeSettings+: { globalExtAuth+: { withRequestBody+: { allowPartialMessage: allowPartialMessage } } } } },
          '#withMaxRequestBytes':: d.fn(help='"MaxRequestBytes sets the maximum size of message body ExtAuthz filter will hold in-memory."', args=[d.arg(name='maxRequestBytes', type=d.T.integer)]),
          withMaxRequestBytes(maxRequestBytes): { spec+: { runtimeSettings+: { globalExtAuth+: { withRequestBody+: { maxRequestBytes: maxRequestBytes } } } } },
          '#withPackAsBytes':: d.fn(help='"If PackAsBytes is true, the body sent to Authorization Server is in raw bytes."', args=[d.arg(name='packAsBytes', type=d.T.boolean)]),
          withPackAsBytes(packAsBytes): { spec+: { runtimeSettings+: { globalExtAuth+: { withRequestBody+: { packAsBytes: packAsBytes } } } } },
        },
        '#withResponseTimeout':: d.fn(help='"ResponseTimeout configures maximum time to wait for a check response from the authorization server.\\nTimeout durations are expressed in the Go [Duration format](https://godoc.org/time#ParseDuration).\\nValid time units are \\"ns\\", \\"us\\" (or \\"s\\"), \\"ms\\", \\"s\\", \\"m\\", \\"h\\".\\nThe string \\"infinity\\" is also a valid input and specifies no timeout."', args=[d.arg(name='responseTimeout', type=d.T.string)]),
        withResponseTimeout(responseTimeout): { spec+: { runtimeSettings+: { globalExtAuth+: { responseTimeout: responseTimeout } } } },
      },
      '#health':: d.obj(help="\"Health defines the endpoints Contour uses to serve health checks.\\nContour's default is { address: \\\"0.0.0.0\\\", port: 8000 }.\""),
      health: {
        '#withAddress':: d.fn(help='"Defines the health address interface."', args=[d.arg(name='address', type=d.T.string)]),
        withAddress(address): { spec+: { runtimeSettings+: { health+: { address: address } } } },
        '#withPort':: d.fn(help='"Defines the health port."', args=[d.arg(name='port', type=d.T.integer)]),
        withPort(port): { spec+: { runtimeSettings+: { health+: { port: port } } } },
      },
      '#httpproxy':: d.obj(help='"HTTPProxy defines parameters on HTTPProxy."'),
      httpproxy: {
        '#fallbackCertificate':: d.obj(help='"FallbackCertificate defines the namespace/name of the Kubernetes secret to\\nuse as fallback when a non-SNI request is received."'),
        fallbackCertificate: {
          '#withName':: d.fn(help='', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { spec+: { runtimeSettings+: { httpproxy+: { fallbackCertificate+: { name: name } } } } },
          '#withNamespace':: d.fn(help='', args=[d.arg(name='namespace', type=d.T.string)]),
          withNamespace(namespace): { spec+: { runtimeSettings+: { httpproxy+: { fallbackCertificate+: { namespace: namespace } } } } },
        },
        '#withDisablePermitInsecure':: d.fn(help="\"DisablePermitInsecure disables the use of the\\npermitInsecure field in HTTPProxy.\\nContour's default is false.\"", args=[d.arg(name='disablePermitInsecure', type=d.T.boolean)]),
        withDisablePermitInsecure(disablePermitInsecure): { spec+: { runtimeSettings+: { httpproxy+: { disablePermitInsecure: disablePermitInsecure } } } },
        '#withRootNamespaces':: d.fn(help='"Restrict Contour to searching these namespaces for root ingress routes."', args=[d.arg(name='rootNamespaces', type=d.T.array)]),
        withRootNamespaces(rootNamespaces): { spec+: { runtimeSettings+: { httpproxy+: { rootNamespaces: if std.isArray(v=rootNamespaces) then rootNamespaces else [rootNamespaces] } } } },
        '#withRootNamespacesMixin':: d.fn(help='"Restrict Contour to searching these namespaces for root ingress routes."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='rootNamespaces', type=d.T.array)]),
        withRootNamespacesMixin(rootNamespaces): { spec+: { runtimeSettings+: { httpproxy+: { rootNamespaces+: if std.isArray(v=rootNamespaces) then rootNamespaces else [rootNamespaces] } } } },
      },
      '#ingress':: d.obj(help='"Ingress contains parameters for ingress options."'),
      ingress: {
        '#withClassNames':: d.fn(help='"Ingress Class Names Contour should use."', args=[d.arg(name='classNames', type=d.T.array)]),
        withClassNames(classNames): { spec+: { runtimeSettings+: { ingress+: { classNames: if std.isArray(v=classNames) then classNames else [classNames] } } } },
        '#withClassNamesMixin':: d.fn(help='"Ingress Class Names Contour should use."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='classNames', type=d.T.array)]),
        withClassNamesMixin(classNames): { spec+: { runtimeSettings+: { ingress+: { classNames+: if std.isArray(v=classNames) then classNames else [classNames] } } } },
        '#withStatusAddress':: d.fn(help='"Address to set in Ingress object status."', args=[d.arg(name='statusAddress', type=d.T.string)]),
        withStatusAddress(statusAddress): { spec+: { runtimeSettings+: { ingress+: { statusAddress: statusAddress } } } },
      },
      '#metrics':: d.obj(help="\"Metrics defines the endpoint Contour uses to serve metrics.\\nContour's default is { address: \\\"0.0.0.0\\\", port: 8000 }.\""),
      metrics: {
        '#tls':: d.obj(help='"TLS holds TLS file config details.\\nMetrics and health endpoints cannot have same port number when metrics is served over HTTPS."'),
        tls: {
          '#withCaFile':: d.fn(help='"CA filename."', args=[d.arg(name='caFile', type=d.T.string)]),
          withCaFile(caFile): { spec+: { runtimeSettings+: { metrics+: { tls+: { caFile: caFile } } } } },
          '#withCertFile':: d.fn(help='"Client certificate filename."', args=[d.arg(name='certFile', type=d.T.string)]),
          withCertFile(certFile): { spec+: { runtimeSettings+: { metrics+: { tls+: { certFile: certFile } } } } },
          '#withKeyFile':: d.fn(help='"Client key filename."', args=[d.arg(name='keyFile', type=d.T.string)]),
          withKeyFile(keyFile): { spec+: { runtimeSettings+: { metrics+: { tls+: { keyFile: keyFile } } } } },
        },
        '#withAddress':: d.fn(help='"Defines the metrics address interface."', args=[d.arg(name='address', type=d.T.string)]),
        withAddress(address): { spec+: { runtimeSettings+: { metrics+: { address: address } } } },
        '#withPort':: d.fn(help='"Defines the metrics port."', args=[d.arg(name='port', type=d.T.integer)]),
        withPort(port): { spec+: { runtimeSettings+: { metrics+: { port: port } } } },
      },
      '#policy':: d.obj(help='"Policy specifies default policy applied if not overridden by the user"'),
      policy: {
        '#requestHeaders':: d.obj(help='"RequestHeadersPolicy defines the request headers set/removed on all routes"'),
        requestHeaders: {
          '#withRemove':: d.fn(help='', args=[d.arg(name='remove', type=d.T.array)]),
          withRemove(remove): { spec+: { runtimeSettings+: { policy+: { requestHeaders+: { remove: if std.isArray(v=remove) then remove else [remove] } } } } },
          '#withRemoveMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='remove', type=d.T.array)]),
          withRemoveMixin(remove): { spec+: { runtimeSettings+: { policy+: { requestHeaders+: { remove+: if std.isArray(v=remove) then remove else [remove] } } } } },
          '#withSet':: d.fn(help='', args=[d.arg(name='set', type=d.T.object)]),
          withSet(set): { spec+: { runtimeSettings+: { policy+: { requestHeaders+: { set: set } } } } },
          '#withSetMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='set', type=d.T.object)]),
          withSetMixin(set): { spec+: { runtimeSettings+: { policy+: { requestHeaders+: { set+: set } } } } },
        },
        '#responseHeaders':: d.obj(help='"ResponseHeadersPolicy defines the response headers set/removed on all routes"'),
        responseHeaders: {
          '#withRemove':: d.fn(help='', args=[d.arg(name='remove', type=d.T.array)]),
          withRemove(remove): { spec+: { runtimeSettings+: { policy+: { responseHeaders+: { remove: if std.isArray(v=remove) then remove else [remove] } } } } },
          '#withRemoveMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='remove', type=d.T.array)]),
          withRemoveMixin(remove): { spec+: { runtimeSettings+: { policy+: { responseHeaders+: { remove+: if std.isArray(v=remove) then remove else [remove] } } } } },
          '#withSet':: d.fn(help='', args=[d.arg(name='set', type=d.T.object)]),
          withSet(set): { spec+: { runtimeSettings+: { policy+: { responseHeaders+: { set: set } } } } },
          '#withSetMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='set', type=d.T.object)]),
          withSetMixin(set): { spec+: { runtimeSettings+: { policy+: { responseHeaders+: { set+: set } } } } },
        },
        '#withApplyToIngress':: d.fn(help="\"ApplyToIngress determines if the Policies will apply to ingress objects\\nContour's default is false.\"", args=[d.arg(name='applyToIngress', type=d.T.boolean)]),
        withApplyToIngress(applyToIngress): { spec+: { runtimeSettings+: { policy+: { applyToIngress: applyToIngress } } } },
      },
      '#rateLimitService':: d.obj(help='"RateLimitService optionally holds properties of the Rate Limit Service\\nto be used for global rate limiting."'),
      rateLimitService: {
        '#defaultGlobalRateLimitPolicy':: d.obj(help='"DefaultGlobalRateLimitPolicy allows setting a default global rate limit policy for every HTTPProxy.\\nHTTPProxy can overwrite this configuration."'),
        defaultGlobalRateLimitPolicy: {
          '#descriptors':: d.obj(help='"Descriptors defines the list of descriptors that will\\nbe generated and sent to the rate limit service. Each\\ndescriptor contains 1+ key-value pair entries."'),
          descriptors: {
            '#entries':: d.obj(help='"Entries is the list of key-value pair generators."'),
            entries: {
              '#genericKey':: d.obj(help='"GenericKey defines a descriptor entry with a static key and value."'),
              genericKey: {
                '#withKey':: d.fn(help='"Key defines the key of the descriptor entry. If not set, the\\nkey is set to \\"generic_key\\"."', args=[d.arg(name='key', type=d.T.string)]),
                withKey(key): { genericKey+: { key: key } },
                '#withValue':: d.fn(help='"Value defines the value of the descriptor entry."', args=[d.arg(name='value', type=d.T.string)]),
                withValue(value): { genericKey+: { value: value } },
              },
              '#requestHeader':: d.obj(help="\"RequestHeader defines a descriptor entry that's populated only if\\na given header is present on the request. The descriptor key is static,\\nand the descriptor value is equal to the value of the header.\""),
              requestHeader: {
                '#withDescriptorKey':: d.fn(help='"DescriptorKey defines the key to use on the descriptor entry."', args=[d.arg(name='descriptorKey', type=d.T.string)]),
                withDescriptorKey(descriptorKey): { requestHeader+: { descriptorKey: descriptorKey } },
                '#withHeaderName':: d.fn(help='"HeaderName defines the name of the header to look for on the request."', args=[d.arg(name='headerName', type=d.T.string)]),
                withHeaderName(headerName): { requestHeader+: { headerName: headerName } },
              },
              '#requestHeaderValueMatch':: d.obj(help="\"RequestHeaderValueMatch defines a descriptor entry that's populated\\nif the request's headers match a set of 1+ match criteria. The\\ndescriptor key is \\\"header_match\\\", and the descriptor value is static.\""),
              requestHeaderValueMatch: {
                '#headers':: d.obj(help='"Headers is a list of 1+ match criteria to apply against the request\\nto determine whether to populate the descriptor entry or not."'),
                headers: {
                  '#withContains':: d.fn(help='"Contains specifies a substring that must be present in\\nthe header value."', args=[d.arg(name='contains', type=d.T.string)]),
                  withContains(contains): { contains: contains },
                  '#withExact':: d.fn(help='"Exact specifies a string that the header value must be equal to."', args=[d.arg(name='exact', type=d.T.string)]),
                  withExact(exact): { exact: exact },
                  '#withIgnoreCase':: d.fn(help='"IgnoreCase specifies that string matching should be case insensitive.\\nNote that this has no effect on the Regex parameter."', args=[d.arg(name='ignoreCase', type=d.T.boolean)]),
                  withIgnoreCase(ignoreCase): { ignoreCase: ignoreCase },
                  '#withName':: d.fn(help='"Name is the name of the header to match against. Name is required.\\nHeader names are case insensitive."', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { name: name },
                  '#withNotcontains':: d.fn(help='"NotContains specifies a substring that must not be present\\nin the header value."', args=[d.arg(name='notcontains', type=d.T.string)]),
                  withNotcontains(notcontains): { notcontains: notcontains },
                  '#withNotexact':: d.fn(help='"NoExact specifies a string that the header value must not be\\nequal to. The condition is true if the header has any other value."', args=[d.arg(name='notexact', type=d.T.string)]),
                  withNotexact(notexact): { notexact: notexact },
                  '#withNotpresent':: d.fn(help='"NotPresent specifies that condition is true when the named header\\nis not present. Note that setting NotPresent to false does not\\nmake the condition true if the named header is present."', args=[d.arg(name='notpresent', type=d.T.boolean)]),
                  withNotpresent(notpresent): { notpresent: notpresent },
                  '#withPresent':: d.fn(help='"Present specifies that condition is true when the named header\\nis present, regardless of its value. Note that setting Present\\nto false does not make the condition true if the named header\\nis absent."', args=[d.arg(name='present', type=d.T.boolean)]),
                  withPresent(present): { present: present },
                  '#withRegex':: d.fn(help='"Regex specifies a regular expression pattern that must match the header\\nvalue."', args=[d.arg(name='regex', type=d.T.string)]),
                  withRegex(regex): { regex: regex },
                  '#withTreatMissingAsEmpty':: d.fn(help='"TreatMissingAsEmpty specifies if the header match rule specified header\\ndoes not exist, this header value will be treated as empty. Defaults to false.\\nUnlike the underlying Envoy implementation this is **only** supported for\\nnegative matches (e.g. NotContains, NotExact)."', args=[d.arg(name='treatMissingAsEmpty', type=d.T.boolean)]),
                  withTreatMissingAsEmpty(treatMissingAsEmpty): { treatMissingAsEmpty: treatMissingAsEmpty },
                },
                '#withExpectMatch':: d.fn(help='"ExpectMatch defines whether the request must positively match the match\\ncriteria in order to generate a descriptor entry (i.e. true), or not\\nmatch the match criteria in order to generate a descriptor entry (i.e. false).\\nThe default is true."', args=[d.arg(name='expectMatch', type=d.T.boolean)]),
                withExpectMatch(expectMatch): { requestHeaderValueMatch+: { expectMatch: expectMatch } },
                '#withHeaders':: d.fn(help='"Headers is a list of 1+ match criteria to apply against the request\\nto determine whether to populate the descriptor entry or not."', args=[d.arg(name='headers', type=d.T.array)]),
                withHeaders(headers): { requestHeaderValueMatch+: { headers: if std.isArray(v=headers) then headers else [headers] } },
                '#withHeadersMixin':: d.fn(help='"Headers is a list of 1+ match criteria to apply against the request\\nto determine whether to populate the descriptor entry or not."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='headers', type=d.T.array)]),
                withHeadersMixin(headers): { requestHeaderValueMatch+: { headers+: if std.isArray(v=headers) then headers else [headers] } },
                '#withValue':: d.fn(help='"Value defines the value of the descriptor entry."', args=[d.arg(name='value', type=d.T.string)]),
                withValue(value): { requestHeaderValueMatch+: { value: value } },
              },
              '#withRemoteAddress':: d.fn(help="\"RemoteAddress defines a descriptor entry with a key of \\\"remote_address\\\"\\nand a value equal to the client's IP address (from x-forwarded-for).\"", args=[d.arg(name='remoteAddress', type=d.T.object)]),
              withRemoteAddress(remoteAddress): { remoteAddress: remoteAddress },
              '#withRemoteAddressMixin':: d.fn(help="\"RemoteAddress defines a descriptor entry with a key of \\\"remote_address\\\"\\nand a value equal to the client's IP address (from x-forwarded-for).\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='remoteAddress', type=d.T.object)]),
              withRemoteAddressMixin(remoteAddress): { remoteAddress+: remoteAddress },
            },
            '#withEntries':: d.fn(help='"Entries is the list of key-value pair generators."', args=[d.arg(name='entries', type=d.T.array)]),
            withEntries(entries): { entries: if std.isArray(v=entries) then entries else [entries] },
            '#withEntriesMixin':: d.fn(help='"Entries is the list of key-value pair generators."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='entries', type=d.T.array)]),
            withEntriesMixin(entries): { entries+: if std.isArray(v=entries) then entries else [entries] },
          },
          '#withDescriptors':: d.fn(help='"Descriptors defines the list of descriptors that will\\nbe generated and sent to the rate limit service. Each\\ndescriptor contains 1+ key-value pair entries."', args=[d.arg(name='descriptors', type=d.T.array)]),
          withDescriptors(descriptors): { spec+: { runtimeSettings+: { rateLimitService+: { defaultGlobalRateLimitPolicy+: { descriptors: if std.isArray(v=descriptors) then descriptors else [descriptors] } } } } },
          '#withDescriptorsMixin':: d.fn(help='"Descriptors defines the list of descriptors that will\\nbe generated and sent to the rate limit service. Each\\ndescriptor contains 1+ key-value pair entries."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='descriptors', type=d.T.array)]),
          withDescriptorsMixin(descriptors): { spec+: { runtimeSettings+: { rateLimitService+: { defaultGlobalRateLimitPolicy+: { descriptors+: if std.isArray(v=descriptors) then descriptors else [descriptors] } } } } },
          '#withDisabled':: d.fn(help='"Disabled configures the HTTPProxy to not use\\nthe default global rate limit policy defined by the Contour configuration."', args=[d.arg(name='disabled', type=d.T.boolean)]),
          withDisabled(disabled): { spec+: { runtimeSettings+: { rateLimitService+: { defaultGlobalRateLimitPolicy+: { disabled: disabled } } } } },
        },
        '#extensionService':: d.obj(help='"ExtensionService identifies the extension service defining the RLS."'),
        extensionService: {
          '#withName':: d.fn(help='', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { spec+: { runtimeSettings+: { rateLimitService+: { extensionService+: { name: name } } } } },
          '#withNamespace':: d.fn(help='', args=[d.arg(name='namespace', type=d.T.string)]),
          withNamespace(namespace): { spec+: { runtimeSettings+: { rateLimitService+: { extensionService+: { namespace: namespace } } } } },
        },
        '#withDomain':: d.fn(help='"Domain is passed to the Rate Limit Service."', args=[d.arg(name='domain', type=d.T.string)]),
        withDomain(domain): { spec+: { runtimeSettings+: { rateLimitService+: { domain: domain } } } },
        '#withEnableResourceExhaustedCode':: d.fn(help="\"EnableResourceExhaustedCode enables translating error code 429 to\\ngrpc code RESOURCE_EXHAUSTED. When disabled it's translated to UNAVAILABLE\"", args=[d.arg(name='enableResourceExhaustedCode', type=d.T.boolean)]),
        withEnableResourceExhaustedCode(enableResourceExhaustedCode): { spec+: { runtimeSettings+: { rateLimitService+: { enableResourceExhaustedCode: enableResourceExhaustedCode } } } },
        '#withEnableXRateLimitHeaders':: d.fn(help='"EnableXRateLimitHeaders defines whether to include the X-RateLimit\\nheaders X-RateLimit-Limit, X-RateLimit-Remaining, and X-RateLimit-Reset\\n(as defined by the IETF Internet-Draft linked below), on responses\\nto clients when the Rate Limit Service is consulted for a request.\\nref. https://tools.ietf.org/id/draft-polli-ratelimit-headers-03.html"', args=[d.arg(name='enableXRateLimitHeaders', type=d.T.boolean)]),
        withEnableXRateLimitHeaders(enableXRateLimitHeaders): { spec+: { runtimeSettings+: { rateLimitService+: { enableXRateLimitHeaders: enableXRateLimitHeaders } } } },
        '#withFailOpen':: d.fn(help='"FailOpen defines whether to allow requests to proceed when the\\nRate Limit Service fails to respond with a valid rate limit\\ndecision within the timeout defined on the extension service."', args=[d.arg(name='failOpen', type=d.T.boolean)]),
        withFailOpen(failOpen): { spec+: { runtimeSettings+: { rateLimitService+: { failOpen: failOpen } } } },
      },
      '#tracing':: d.obj(help='"Tracing defines properties for exporting trace data to OpenTelemetry."'),
      tracing: {
        '#customTags':: d.obj(help='"CustomTags defines a list of custom tags with unique tag name."'),
        customTags: {
          '#withLiteral':: d.fn(help='"Literal is a static custom tag value.\\nPrecisely one of Literal, RequestHeaderName must be set."', args=[d.arg(name='literal', type=d.T.string)]),
          withLiteral(literal): { literal: literal },
          '#withRequestHeaderName':: d.fn(help='"RequestHeaderName indicates which request header\\nthe label value is obtained from.\\nPrecisely one of Literal, RequestHeaderName must be set."', args=[d.arg(name='requestHeaderName', type=d.T.string)]),
          withRequestHeaderName(requestHeaderName): { requestHeaderName: requestHeaderName },
          '#withTagName':: d.fn(help='"TagName is the unique name of the custom tag."', args=[d.arg(name='tagName', type=d.T.string)]),
          withTagName(tagName): { tagName: tagName },
        },
        '#extensionService':: d.obj(help='"ExtensionService identifies the extension service defining the otel-collector."'),
        extensionService: {
          '#withName':: d.fn(help='', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { spec+: { runtimeSettings+: { tracing+: { extensionService+: { name: name } } } } },
          '#withNamespace':: d.fn(help='', args=[d.arg(name='namespace', type=d.T.string)]),
          withNamespace(namespace): { spec+: { runtimeSettings+: { tracing+: { extensionService+: { namespace: namespace } } } } },
        },
        '#withCustomTags':: d.fn(help='"CustomTags defines a list of custom tags with unique tag name."', args=[d.arg(name='customTags', type=d.T.array)]),
        withCustomTags(customTags): { spec+: { runtimeSettings+: { tracing+: { customTags: if std.isArray(v=customTags) then customTags else [customTags] } } } },
        '#withCustomTagsMixin':: d.fn(help='"CustomTags defines a list of custom tags with unique tag name."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='customTags', type=d.T.array)]),
        withCustomTagsMixin(customTags): { spec+: { runtimeSettings+: { tracing+: { customTags+: if std.isArray(v=customTags) then customTags else [customTags] } } } },
        '#withIncludePodDetail':: d.fn(help='"IncludePodDetail defines a flag.\\nIf it is true, contour will add the pod name and namespace to the span of the trace.\\nthe default is true.\\nNote: The Envoy pods MUST have the HOSTNAME and CONTOUR_NAMESPACE environment variables set for this to work properly."', args=[d.arg(name='includePodDetail', type=d.T.boolean)]),
        withIncludePodDetail(includePodDetail): { spec+: { runtimeSettings+: { tracing+: { includePodDetail: includePodDetail } } } },
        '#withMaxPathTagLength':: d.fn(help="\"MaxPathTagLength defines maximum length of the request path\\nto extract and include in the HttpUrl tag.\\ncontour's default is 256.\"", args=[d.arg(name='maxPathTagLength', type=d.T.integer)]),
        withMaxPathTagLength(maxPathTagLength): { spec+: { runtimeSettings+: { tracing+: { maxPathTagLength: maxPathTagLength } } } },
        '#withOverallSampling':: d.fn(help="\"OverallSampling defines the sampling rate of trace data.\\ncontour's default is 100.\"", args=[d.arg(name='overallSampling', type=d.T.string)]),
        withOverallSampling(overallSampling): { spec+: { runtimeSettings+: { tracing+: { overallSampling: overallSampling } } } },
        '#withServiceName':: d.fn(help="\"ServiceName defines the name for the service.\\ncontour's default is contour.\"", args=[d.arg(name='serviceName', type=d.T.string)]),
        withServiceName(serviceName): { spec+: { runtimeSettings+: { tracing+: { serviceName: serviceName } } } },
      },
      '#withEnableExternalNameService':: d.fn(help="\"EnableExternalNameService allows processing of ExternalNameServices\\nContour's default is false for security reasons.\"", args=[d.arg(name='enableExternalNameService', type=d.T.boolean)]),
      withEnableExternalNameService(enableExternalNameService): { spec+: { runtimeSettings+: { enableExternalNameService: enableExternalNameService } } },
      '#withFeatureFlags':: d.fn(help='"FeatureFlags defines toggle to enable new contour features.\\nAvailable toggles are:\\nuseEndpointSlices - configures contour to fetch endpoint data\\nfrom k8s endpoint slices. defaults to false and reading endpoint\\ndata from the k8s endpoints."', args=[d.arg(name='featureFlags', type=d.T.array)]),
      withFeatureFlags(featureFlags): { spec+: { runtimeSettings+: { featureFlags: if std.isArray(v=featureFlags) then featureFlags else [featureFlags] } } },
      '#withFeatureFlagsMixin':: d.fn(help='"FeatureFlags defines toggle to enable new contour features.\\nAvailable toggles are:\\nuseEndpointSlices - configures contour to fetch endpoint data\\nfrom k8s endpoint slices. defaults to false and reading endpoint\\ndata from the k8s endpoints."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='featureFlags', type=d.T.array)]),
      withFeatureFlagsMixin(featureFlags): { spec+: { runtimeSettings+: { featureFlags+: if std.isArray(v=featureFlags) then featureFlags else [featureFlags] } } },
      '#xdsServer':: d.obj(help='"XDSServer contains parameters for the xDS server."'),
      xdsServer: {
        '#tls':: d.obj(help="\"TLS holds TLS file config details.\\nContour's default is { caFile: \\\"/certs/ca.crt\\\", certFile: \\\"/certs/tls.cert\\\", keyFile: \\\"/certs/tls.key\\\", insecure: false }.\""),
        tls: {
          '#withCaFile':: d.fn(help='"CA filename."', args=[d.arg(name='caFile', type=d.T.string)]),
          withCaFile(caFile): { spec+: { runtimeSettings+: { xdsServer+: { tls+: { caFile: caFile } } } } },
          '#withCertFile':: d.fn(help='"Client certificate filename."', args=[d.arg(name='certFile', type=d.T.string)]),
          withCertFile(certFile): { spec+: { runtimeSettings+: { xdsServer+: { tls+: { certFile: certFile } } } } },
          '#withInsecure':: d.fn(help='"Allow serving the xDS gRPC API without TLS."', args=[d.arg(name='insecure', type=d.T.boolean)]),
          withInsecure(insecure): { spec+: { runtimeSettings+: { xdsServer+: { tls+: { insecure: insecure } } } } },
          '#withKeyFile':: d.fn(help='"Client key filename."', args=[d.arg(name='keyFile', type=d.T.string)]),
          withKeyFile(keyFile): { spec+: { runtimeSettings+: { xdsServer+: { tls+: { keyFile: keyFile } } } } },
        },
        '#withAddress':: d.fn(help="\"Defines the xDS gRPC API address which Contour will serve.\\nContour's default is \\\"0.0.0.0\\\".\"", args=[d.arg(name='address', type=d.T.string)]),
        withAddress(address): { spec+: { runtimeSettings+: { xdsServer+: { address: address } } } },
        '#withPort':: d.fn(help="\"Defines the xDS gRPC API port which Contour will serve.\\nContour's default is 8001.\"", args=[d.arg(name='port', type=d.T.integer)]),
        withPort(port): { spec+: { runtimeSettings+: { xdsServer+: { port: port } } } },
        '#withType':: d.fn(help='"Defines the XDSServer to use for `contour serve`.\\nValues: `contour` (default), `envoy`.\\nOther values will produce an error."', args=[d.arg(name='type', type=d.T.string)]),
        withType(type): { spec+: { runtimeSettings+: { xdsServer+: { type: type } } } },
      },
    },
    '#withResourceLabels':: d.fn(help='"ResourceLabels is a set of labels to add to the provisioned Contour resources.\\nDeprecated: use Gateway.Spec.Infrastructure.Labels instead. This field will be\\nremoved in a future release."', args=[d.arg(name='resourceLabels', type=d.T.object)]),
    withResourceLabels(resourceLabels): { spec+: { resourceLabels: resourceLabels } },
    '#withResourceLabelsMixin':: d.fn(help='"ResourceLabels is a set of labels to add to the provisioned Contour resources.\\nDeprecated: use Gateway.Spec.Infrastructure.Labels instead. This field will be\\nremoved in a future release."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='resourceLabels', type=d.T.object)]),
    withResourceLabelsMixin(resourceLabels): { spec+: { resourceLabels+: resourceLabels } },
  },
  '#mixin': 'ignore',
  mixin: self,
}
